{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Term end\n",
    "abstract type Formula end\n",
    "\n",
    "@auto_hash_equals struct PredicateSymbol\n",
    "    symbol::String\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct FunctionSymbol\n",
    "    symbol::String\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct Variable <: Term\n",
    "    variable::String\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct Function <: Term\n",
    "    name::FunctionSymbol\n",
    "    arguments::Vector{Term}\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct AtomicFormula <: Formula\n",
    "    name::PredicateSymbol\n",
    "    arguments::Vector{Term}\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct Negation <: Formula\n",
    "    formula::Formula\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct EFormula <: Formula\n",
    "    variable::Variable\n",
    "    formula::Formula\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct AFormula <: Formula\n",
    "    variable::Variable\n",
    "    formula::Formula\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct Conjunction <: Formula\n",
    "    formula1::Formula\n",
    "    formula2::Formula\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct Disjunction <: Formula \n",
    "    formula1::Formula\n",
    "    formula2::Formula\n",
    "end\n",
    "\n",
    "@auto_hash_equals struct Literal\n",
    "    negative::Bool\n",
    "    formula::AtomicFormula\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Base.Meta.ParseError(\"Ill-formed theory binding Category{Ob, Hom}\")",
     "output_type": "error",
     "traceback": [
      "Base.Meta.ParseError(\"Ill-formed theory binding Category{Ob, Hom}\")",
      "",
      "Stacktrace:",
      " [1] macro expansion at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:202 [inlined]",
      " [2] macro expansion at /home/philip/.julia/packages/Match/qiTCM/src/matchmacro.jl:410 [inlined]",
      " [3] parse_theory_binding(::Expr) at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:201",
      " [4] macro expansion at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:195 [inlined]",
      " [5] macro expansion at /home/philip/.julia/packages/Match/qiTCM/src/matchmacro.jl:410 [inlined]",
      " [6] macro expansion at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:194 [inlined]",
      " [7] macro expansion at /home/philip/.julia/packages/Match/qiTCM/src/matchmacro.jl:410 [inlined]",
      " [8] parse_theory_head(::Expr) at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:192",
      " [9] theory_builder(::Expr, ::Expr; signature::Bool) at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:135",
      " [10] theory_builder(::Expr, ::Expr) at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:135",
      " [11] @theory(::LineNumberNode, ::Module, ::Any, ::Any) at /home/philip/.julia/packages/Catlab/oORoS/src/core/GAT.jl:101"
     ]
    }
   ],
   "source": [
    "using Catlab\n",
    "\n",
    "@theory Category{Ob,Hom} begin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abstract type Term end\n",
    "\n",
    "#variables\n",
    "struct Sym <: Term\n",
    "    name\n",
    "end\n",
    "\n",
    "struct Lit <: Term\n",
    "    name\n",
    "end\n",
    "\n",
    "struct Func <: Term\n",
    "    head\n",
    "    args\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "struct ForAll <: Term\n",
    "    vars\n",
    "    body\n",
    "end\n",
    "\n",
    "struct Exists <: Term\n",
    "    vars\n",
    "    body\n",
    "end\n",
    "\n",
    "struct And <: Term\n",
    "    args \n",
    "end\n",
    "\n",
    "struct Or <: Term\n",
    "    args\n",
    "end\n",
    "\n",
    "struct Not <: Term\n",
    "    body\n",
    "end\n",
    "\n",
    "struct Eq <: Term\n",
    "    left\n",
    "    right\n",
    "end\n",
    "\n",
    "struct NotEq <: Term\n",
    "    left\n",
    "    right\n",
    "end\n",
    "\n",
    "struct Implies <: Term\n",
    "    hyp\n",
    "    conc\n",
    "end\n",
    "\n",
    "struct Equiv <: Term\n",
    "    left\n",
    "    right\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{Any}((3,))\n",
      "    1: Symbol compose\n",
      "    2: Symbol f\n",
      "    3: Expr\n",
      "      head: Symbol call\n",
      "      args: Array{Any}((3,))\n",
      "        1: Symbol compose\n",
      "        2: Symbol g\n",
      "        3: Symbol h\n"
     ]
    }
   ],
   "source": [
    "dump(:(compose(f,compose(g,h))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int64,1}:\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maybe we should just idrectly use stuff?\n",
    "[1,2,3][2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{Any}((2,))\n",
      "    1: Symbol forall\n",
      "    2: Expr\n",
      "      head: Symbol ->\n",
      "      args: Array{Any}((2,))\n",
      "        1: Expr\n",
      "          head: Symbol tuple\n",
      "          args: Array{Any}((2,))\n",
      "            1: Symbol x\n",
      "            2: Symbol y\n",
      "        2: Expr\n",
      "          head: Symbol block\n",
      "          args: Array{Any}((2,))\n",
      "            1: LineNumberNode\n",
      "              line: Int64 1\n",
      "              file: Symbol In[43]\n",
      "            2: Expr\n",
      "              head: Symbol call\n",
      "              args: Array{Any}((3,))\n",
      "                1: Symbol p\n",
      "                2: Symbol x\n",
      "                3: Expr\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# macro ized hoas\n",
    "dump(:(forall( (x, y) -> p(x, forall(x -> z(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tptp (generic function with 2 methods)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tptp( x::Expr ) \n",
    "    if x.head == :call\n",
    "        return \"$(x.args[1])($(join(map(tptp,x.args[2:end]),\",\")))\"\n",
    "    end\n",
    "end\n",
    "tptp(x :: Symbol) = String(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\":(compose(f, compose(g, h)))\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tptp(:(compose(f,compose(g,h))))\n",
    "repr(:(compose(f,compose(g,h)))) # I'm very close to being able to just do this. But we probably want the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Or"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "And( x::T, y::S ) where {T <: Term, S <: Term} = And([x,y])\n",
    "Or( x::T, y::S ) where {T <: Term, S <: Term} = Or([x,y])\n",
    "Func(n::String) = Func(n,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tptp (generic function with 11 methods)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tptp( x::Not  ) = \"( ~ $(tptp(x.body)) )\"\n",
    "tptp( x::Eq  ) = \"($(tptp(x.left)) = $(tptp(x.right)))\"\n",
    "tptp( x::NotEq  ) = \"($(tptp(x.left)) != $(tptp(x.right)))\"\n",
    "tptp( x::Implies  ) = \"( $(tptp(x.hyp)) => $(tptp(x.conc)) )\"\n",
    "tptp( x::ForAll ) = \"(! [$(join(map(tptp,x.vars),\",\"))] : $(tptp(x.body)))\"\n",
    "tptp( x::Exists ) = \"(? [$(join(map(tptp,x.vars),\",\"))] : $(tptp(x.body)))\"\n",
    "tptp( x::And ) = \"($(join(map(tptp,x.args),\" & \")))\"\n",
    "tptp( x::Or ) = \"($(join(map(tptp,x.args),\" | \")))\"\n",
    "tptp( x::Sym ) = uppercasefirst(String(x.name))\n",
    "tptp( x::Lit ) = String(x.name)\n",
    "tptp( f::Func ) = \"$(f.head)($(join(map(tptp,f.args),\",\")))\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "expression is not a function call, or is too complex for @code_llvm to analyze; break it down to simpler parts if possible",
     "output_type": "error",
     "traceback": [
      "expression is not a function call, or is too complex for @code_llvm to analyze; break it down to simpler parts if possible",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] top-level scope at In[27]:1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods(|)\n",
    "Base.:|( x::T, y::S ) where {T <: Term, S <: Term} = Or(x,y)\n",
    "Base.:&( x::T, y::S ) where {T <: Term, S <: Term} = And(x,y)\n",
    "\n",
    "Base.:!( x::T) where {T <: Term} = Not(x)\n",
    "=>( x::T, y::S ) where {T <: Term, S <: Term} = Implies(x,y)\n",
    "#Base.:<=>( x::T, y::S ) where {T <: Term, S <: Term} = Equiv(x,y)\n",
    "\n",
    "==( x::T, y::S ) where {T <: Term, S <: Term} = Eq(x,y)\n",
    "import Base.!=\n",
    "!=( x::T, y::S ) where {T <: Term, S <: Term} = NotEq(x,y)\n",
    "(f::Func)(x...) = Func(f.head, vcat(f.args , [y for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(! [X,X] : (? [Y] : ( (X = Y) => X )))\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Sym(:x)\n",
    "y = Sym(:y)\n",
    "t = ForAll([x,x],  Exists([y], x == y => x  ))\n",
    "tptp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Func(\"ty\", Any[])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty = Func(\"ty\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ty(X,X,X)\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tptp(ty(x,x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "struct Axiom\n",
    "    name\n",
    "    formula\n",
    "end\n",
    "struct Theory\n",
    "    axioms\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Func"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lit(\"charles\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lives = Func(\"lives\")\n",
    "killed = Func(\"killed\")\n",
    "richer = Func(\"richer\")\n",
    "hates = Func(\"hates\")\n",
    "x = Sym(:X)\n",
    "y = Sym(:Y)\n",
    "butler = Lit(\"butler\")\n",
    "agatha = Lit(\"agatha\")\n",
    "charles = Lit(\"charles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(? [X] : (lives(X) & killed(X,agatha)))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Exists([x], lives(x) & killed(x, agatha) )\n",
    "tptp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching =>(::String, ::Func)\nYou may have intended to import Base.:(=>)\nClosest candidates are:\n  =>(!Matched::T, ::S) where {T<:Term, S<:Term} at In[23]:6",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching =>(::String, ::Func)\nYou may have intended to import Base.:(=>)\nClosest candidates are:\n  =>(!Matched::T, ::S) where {T<:Term, S<:Term} at In[23]:6",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[31]:1"
     ]
    }
   ],
   "source": [
    "agatha_theory = Dict(\"e1\" => lives(agatha),\n",
    "\"e2\" => lives(butler),\n",
    "\"e3\" => lives(charles),\n",
    "\"e4\" => ForAll([x], lives(x) => (   (x == agatha) | (x == charles) | (x == butler ))   ),\n",
    "\"e5\" => ForAll([x,y], killed(x,y) => hates(x,y) ) \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Func(\"killed\", Any[Lit(\"agatha\"), Lit(\"agatha\")])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agatha_theory = [Exists([x], lives(x) & killed(x, agatha) ),\n",
    "lives(agatha),\n",
    "lives(butler),\n",
    "lives(charles),\n",
    "ForAll([x], lives(x) => (   (x == agatha) | (x == charles) | (x == butler ))   ),\n",
    "ForAll([x,y], killed(x,y) => hates(x,y) ) ,\n",
    "\n",
    "\n",
    "ForAll([x,y], killed(x,y) => !richer(x,y) ), \n",
    "ForAll([x], hates(agatha,x) => !hates(charles,x) ), \n",
    "ForAll([x], x != butler => hates(agatha,x) ) ,\n",
    "ForAll([x], !richer(x,agatha) => hates(butler,x) ), \n",
    "ForAll([x], hates(agatha,x) => hates(butler,x) ),\n",
    "ForAll([x], Exists([y], !hates(x,y))),\n",
    "agatha != butler]\n",
    "\n",
    "map(tptp, agatha_theory)\n",
    "\n",
    "conjecture = killed(agatha,agatha)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fof(e1 , axiom, (? [X] : (lives(X) & killed(X,agatha))) ).\\nfof(e2 , axiom, lives(agatha) ).\\nfof(e3 , axiom, lives(butler) ).\\nfof(e4 , axiom, lives(charles) ).\\nfof(e5 , axiom, (! [X] : ( lives(X) => (((X = agatha) | (X = charles)) | (X = butler)) )) ).\\nfof(e6 , axiom, (! [X,Y] : ( killed(X,Y) => hates(X,Y) )) ).\\nfof(e7 , axiom, (! [X,Y] : ( killed(X,Y) => ( ~ richer(X,Y) ) )) ).\\nfof(e8 , axiom, (! [X] : ( hates(agatha,X) => ( ~ hates(charles,X) ) )) ).\\nfof(e9 , axiom, (! [X] : ( (X != butler) => hates(agatha,X) )) ).\\nfof(e10 , axiom, (! [X] : ( ( ~ richer(X,agatha) ) => hates(butler,X) )) ).\\nfof(e11 , axiom, (! [X] : ( hates(agatha,X) => hates(butler,X) )) ).\\nfof(e12 , axiom, (! [X] : (? [Y] : ( ~ hates(X,Y) ))) ).\\nfof(e13 , axiom, (agatha != butler) ).\\nfof(gfoo, conjecture, killed(agatha,agatha)).\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = join([ \"fof(e$i , axiom, $(tptp(f)) ).\"   for (i,f) in  enumerate(agatha_theory)], \"\\n\") *  \"\\nfof(gfoo, conjecture, $(tptp(conjecture))).\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   no_preproc:                    false\n",
      "   eqdef_maxclauses:              20000\n",
      "   eqdef_incrlimit:               20\n",
      "   heuristic_name:                Default\n",
      "   heuristic_def:                 \n",
      "   prefer_initial_clauses:        false\n",
      "   selection_strategy:            NoSelection\n",
      "   pos_lit_sel_min:               0\n",
      "   pos_lit_sel_max:               9223372036854775807\n",
      "   neg_lit_sel_min:               0\n",
      "   neg_lit_sel_max:               9223372036854775807\n",
      "   all_lit_sel_min:               0\n",
      "   all_lit_sel_max:               9223372036854775807\n",
      "   weight_sel_min:                0\n",
      "   select_on_proc_only:           false\n",
      "   inherit_paramod_lit:           false\n",
      "   inherit_goal_pm_lit:           false\n",
      "   inherit_conj_pm_lit:           false\n",
      "   enable_eq_factoring:           true\n",
      "   enable_neg_unit_paramod:       true\n",
      "   enable_given_forward_simpl:    true\n",
      "   pm_type:                       ParamodPlain\n",
      "   ac_handling:                   1\n",
      "   ac_res_aggressive:             true\n",
      "   forward_context_sr:            false\n",
      "   forward_context_sr_aggressive: false\n",
      "   backward_context_sr:           false\n",
      "   forward_demod:                 2\n",
      "   prefer_general:                false\n",
      "   condensing:                    false\n",
      "   condensing_aggressive:         false\n",
      "   er_varlit_destructive:         false\n",
      "   er_strong_destructive:         false\n",
      "   er_aggressive:                 false\n",
      "   split_clauses                  0\n",
      "   split_method                   0\n",
      "   split_aggressive:              false\n",
      "   split_fresh_defs:              true\n",
      "   rw_bw_index_types:             FP7\n",
      "   pm_from_index_type:            FP7\n",
      "   pm_into_index_type:            FP7\n",
      "   sat_check_grounding:           NoGrounding\n",
      "   sat_check_step_limit           9223372036854775807\n",
      "   sat_check_size_limit           9223372036854775807\n",
      "   sat_check_ttinsert_limit       9223372036854775807\n",
      "   sat_check_normconst:           false\n",
      "   sat_check_normalize:           false\n",
      "   sat_check_decision_limit       10000\n",
      "   filter_orphans_limit:          9223372036854775807\n",
      "   forward_contract_limit:        9223372036854775807\n",
      "   delete_bad_limit:              9223372036854775807\n",
      "   mem_limit:                     0\n",
      "   watchlist_simplify:            true\n",
      "   watchlist_is_static:           false\n",
      "   use_tptp_sos:                  false\n",
      "   presat_interreduction:         false\n",
      "   detsort_bw_rw:                 false\n",
      "   detsort_tmpset:                false\n",
      "}\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_3, plain, (lives(agatha))).\n",
      "#\n",
      "#cnf(i_0_4, plain, (lives(butler))).\n",
      "#\n",
      "#cnf(i_0_5, plain, (lives(charles))).\n",
      "#\n",
      "#cnf(i_0_14, plain, (agatha!=butler)).\n",
      "#\n",
      "#cnf(i_0_2, plain, (lives(esk1_0))).\n",
      "#\n",
      "#cnf(i_0_1, plain, (killed(esk1_0,agatha))).\n",
      "#\n",
      "#cnf(i_0_7, plain, (hates(X1,X2)|~killed(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_15, negated_conjecture, (~killed(agatha,agatha))).\n",
      "#\n",
      "#cnf(i_0_10, plain, (X1=butler|hates(agatha,X1))).\n",
      "#\n",
      "#cnf(i_0_12, plain, (hates(butler,X1)|~hates(agatha,X1))).\n",
      "#\n",
      "#cnf(i_0_17, plain, (X1=butler|hates(butler,X1))).\n",
      "#\n",
      "#cnf(i_0_13, plain, (~hates(X1,esk2_1(X1)))).\n",
      "#\n",
      "#cnf(i_0_18, plain, (esk2_1(butler)=butler)).\n",
      "#\n",
      "#cnf(i_0_19, plain, (esk2_1(agatha)=butler)).\n",
      "#\n",
      "#cnf(i_0_16, plain, (hates(butler,X1)|~killed(agatha,X1))).\n",
      "#\n",
      "#cnf(i_0_20, plain, (~killed(X1,esk2_1(X1)))).\n",
      "#\n",
      "#cnf(i_0_11, plain, (richer(X1,agatha)|hates(butler,X1))).\n",
      "#\n",
      "#cnf(i_0_6, plain, (X1=agatha|X1=butler|X1=charles|~lives(X1))).\n",
      "#\n",
      "#cnf(i_0_26, plain, (agatha=esk1_0|esk1_0=butler|esk1_0=charles)).\n",
      "#\n",
      "#cnf(i_0_21, plain, (~hates(butler,butler))).\n",
      "#\n",
      "#cnf(i_0_31, negated_conjecture, (esk1_0=butler|esk1_0=charles)).\n",
      "#\n",
      "#cnf(i_0_38, negated_conjecture, (esk1_0=butler|charles!=butler)).\n",
      "#\n",
      "#cnf(i_0_42, negated_conjecture, (killed(butler,agatha)|charles!=butler)).\n",
      "#\n",
      "#cnf(i_0_22, plain, (~hates(agatha,butler))).\n",
      "#\n",
      "#cnf(i_0_40, negated_conjecture, (esk1_0=butler|killed(charles,agatha))).\n",
      "#\n",
      "#cnf(i_0_23, plain, (~killed(agatha,butler))).\n",
      "#\n",
      "#cnf(i_0_24, plain, (~killed(butler,butler))).\n",
      "#####\n",
      "#cnf(i_0_8, plain, (~richer(X1,X2)|~killed(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_45, plain, (hates(butler,X1)|~killed(X1,agatha))).\n",
      "#\n",
      "#cnf(i_0_46, plain, (~killed(butler,agatha))).\n",
      "#\n",
      "#cnf(i_0_48, negated_conjecture, (charles!=butler)).\n",
      "##\n",
      "#cnf(i_0_9, plain, (~hates(agatha,X1)|~hates(charles,X1))).\n",
      "#\n",
      "#cnf(i_0_50, plain, (X1=butler|~hates(charles,X1))).\n",
      "#\n",
      "#cnf(i_0_51, plain, (X1=butler|~killed(charles,X1))).\n",
      "#\n",
      "#cnf(i_0_49, plain, (~hates(charles,X1)|~killed(agatha,X1))).\n",
      "#\n",
      "#cnf(i_0_52, negated_conjecture, (esk1_0=butler)).\n",
      "\n",
      "# Proof found!\n",
      "# SZS status Theorem\n",
      "# Parsed axioms                        : 14\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 15\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 15\n",
      "# Processed clauses                    : 41\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 5\n",
      "# ...remaining for further processing  : 36\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 2\n",
      "# Backward-rewritten                   : 4\n",
      "# Generated clauses                    : 38\n",
      "# ...of the previous two non-trivial   : 33\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 37\n",
      "# Factorizations                       : 1\n",
      "# Equation resolutions                 : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 30\n",
      "#    Positive orientable unit clauses  : 6\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 10\n",
      "#    Non-unit-clauses                  : 14\n",
      "# Current number of unprocessed clauses: 1\n",
      "# ...number of literals in the above   : 2\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 6\n",
      "# Clause-clause subsumption calls (NU) : 6\n",
      "# Rec. Clause-clause subsumption calls : 6\n",
      "# Non-unit clause-clause subsumptions  : 1\n",
      "# Unit Clause-clause subsumption calls : 12\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 1\n",
      "# BW rewrite match successes           : 1\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "open(`eprover`, \"w\", stdout) do io\n",
    "        print(io, query)      \n",
    "       end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline(`\u001b[4mecho\u001b[24m \u001b[4m'fof(e1 , axiom, (? [X] : (lives(X) & killed(X,agatha))) ).\u001b[24m\n",
       "\u001b[4mfof(e2 , axiom, lives(agatha) ).\u001b[24m\n",
       "\u001b[4mfof(e3 , axiom, lives(butler) ).\u001b[24m\n",
       "\u001b[4mfof(e4 , axiom, lives(charles) ).\u001b[24m\n",
       "\u001b[4mfof(e5 , axiom, (! [X] : ( lives(X) => (((X = agatha) | (X = charles)) | (X = butler)) )) ).\u001b[24m\n",
       "\u001b[4mfof(e6 , axiom, (! [X,Y] : ( killed(X,Y) => hates(X,Y) )) ).\u001b[24m\n",
       "\u001b[4mfof(e7 , axiom, (! [X,Y] : ( killed(X,Y) => ( ~ richer(X,Y) ) )) ).\u001b[24m\n",
       "\u001b[4mfof(e8 , axiom, (! [X] : ( hates(agatha,X) => ( ~ hates(charles,X) ) )) ).\u001b[24m\n",
       "\u001b[4mfof(e9 , axiom, (! [X] : ( (X != butler) => hates(agatha,X) )) ).\u001b[24m\n",
       "\u001b[4mfof(e10 , axiom, (! [X] : ( ( ~ richer(X,agatha) ) => hates(butler,X) )) ).\u001b[24m\n",
       "\u001b[4mfof(e11 , axiom, (! [X] : ( hates(agatha,X) => hates(butler,X) )) ).\u001b[24m\n",
       "\u001b[4mfof(e12 , axiom, (! [X] : (? [Y] : ( ~ hates(X,Y) ))) ).\u001b[24m\n",
       "\u001b[4mfof(e13 , axiom, (agatha != butler) ).\u001b[24m\n",
       "\u001b[4mfof(gfoo, conjecture, killed(agatha,agatha)).'\u001b[24m`, stdout=`\u001b[4meprover\u001b[24m`)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline( `echo $query`  , `eprover`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E 2.5pre002 \"Avongrove\"\n",
      "\n",
      "Usage: eprover [options] [files]\n",
      "\n",
      "Read a set of first-order clauses and formulae and try to refute it.\n",
      "\n",
      "Options:\n",
      "\n",
      "   -h\n",
      "  --help\n",
      "    Print a short description of program usage and options.\n",
      "\n",
      "   -V\n",
      "  --version\n",
      "    Print the version number of the prover. Please include this with all bug\n",
      "    reports (if any).\n",
      "\n",
      "   -v\n",
      "  --verbose[=<arg>]\n",
      "    Verbose comments on the progress of the program. This differs from the\n",
      "    output level (below) in that technical information is printed to stderr,\n",
      "    while the output level determines which logical manipulations of the\n",
      "    clauses are printed to stdout. The short form or the long form without\n",
      "    the optional argument is equivalent to --verbose=1.\n",
      "\n",
      "   -o <arg>\n",
      "  --output-file=<arg>\n",
      "    Redirect output into the named file.\n",
      "\n",
      "   -s\n",
      "  --silent\n",
      "    Equivalent to --output-level=0.\n",
      "\n",
      "   -l <arg>\n",
      "  --output-level=<arg>\n",
      "    Select an output level, greater values imply more verbose output. Level 0\n",
      "    produces nearly no output, level 1 will output each clause as it is\n",
      "    processed, level 2 will output generating inferences, level 3 will give a\n",
      "    full protocol including rewrite steps and level 4 will include some\n",
      "    internal clause renamings. Levels >= 2 also imply PCL2 or TSTP formats\n",
      "    (which can be post-processed with suitable tools).\n",
      "\n",
      "   -p\n",
      "  --proof-object[=<arg>]\n",
      "    Generate (and print, in case of success) an internal proof object. Level\n",
      "    0 will not print a proof object, level 1 will build asimple, compact\n",
      "    proof object that only contains inference rules and dependencies, level 2\n",
      "    will build a proof object where inferences are unambiguously described by\n",
      "    giving inference positions, and level 3 will expand this to a proof\n",
      "    object where all intermediate results are explicit. This feature is under\n",
      "    development, so far only level 0 and 1 are operational. By default The\n",
      "    proof object will be provided in TPTP-3 or LOP syntax, depending on input\n",
      "    format and explicit settings. The following option will suppress normal\n",
      "    output of the proof object in favour of a graphial representation. The\n",
      "    short form or the long form without the optional argument is equivalent\n",
      "    to --proof-object=1.\n",
      "\n",
      "  --proof-graph[=<arg>]\n",
      "    Generate (and print, in case of success) an internal proof object in the\n",
      "    form of a GraphViz dot graph. The optional argument can be 1 (nodes are\n",
      "    labelled with just the name of the clause/formula), 2 (nodes are labelled\n",
      "    with the TPTP clause/formula) or 3  (nodes also labelled with\n",
      "    source/inference record. The option without the optional argument is\n",
      "    equivalent to --proof-graph=3.\n",
      "\n",
      "   -d\n",
      "  --full-deriv\n",
      "    Include all derived formuas/clauses in the proof graph/proof object, not\n",
      "    just the ones contributing to the actual proof.\n",
      "\n",
      "  --force-deriv[=<arg>]\n",
      "    Force output of the derivation even in cases where the prover terminates\n",
      "    in an indeterminate state. By default, the deriviation of all processed\n",
      "    clauses is included in the derivation object. With value 2, derivation of\n",
      "    all clauses will be printed The option without the optional argument is\n",
      "    equivalent to --force-deriv=1.\n",
      "\n",
      "  --record-gcs\n",
      "    Record given-clause selection as separate (pseudo-)inferences and\n",
      "    preserve the form of given clauses evaluated and selected via archiving\n",
      "    for analysis and possibly machine learning.\n",
      "\n",
      "  --training-examples[=<arg>]\n",
      "    Generate and process training examples from the proof search object.\n",
      "    Implies --record-gcs. The argument is a binary or of the desired\n",
      "    processig. Bit zero prints positive exampels. Bit 1 prints negative\n",
      "    examples. Additional selectors will be added later. The option without\n",
      "    the optional argument is equivalent to --training-examples=1.\n",
      "\n",
      "  --pcl-terms-compressed\n",
      "    Print terms in the PCL output in shared representation.\n",
      "\n",
      "  --pcl-compact\n",
      "    Print PCL steps without additional spaces for formatting (safes disk\n",
      "    space for large protocols).\n",
      "\n",
      "  --pcl-shell-level[=<arg>]\n",
      "    Determines level to which clauses and formulas are suppressed in the\n",
      "    output. Level 0 will print all, level 1 will only print initial\n",
      "    clauses/formulas, level 2 will print no clauses or axioms. All levels\n",
      "    will still print the dependency graph. The option without the optional\n",
      "    argument is equivalent to --pcl-shell-level=1.\n",
      "\n",
      "  --print-statistics\n",
      "    Print the inference statistics (only relevant for output level 0,\n",
      "    otherwise they are printed automatically.\n",
      "\n",
      "   -0\n",
      "  --print-detailed-statistics\n",
      "    Print data about the proof state that is potentially expensive to\n",
      "    collect. Includes number of term cells and number of rewrite steps.\n",
      "\n",
      "   -S\n",
      "  --print-saturated[=<arg>]\n",
      "    Print the (semi-) saturated clause sets after terminating the saturation\n",
      "    process. The argument given describes which parts should be printed in\n",
      "    which order. Legal characters are 'teigEIGaA', standing for type\n",
      "    declarations, processed positive units, processed negative units,\n",
      "    processed non-units, unprocessed positive units, unprocessed negative\n",
      "    units, unprocessed non-units, and two types of additional equality\n",
      "    axioms, respectively. Equality axioms will only be printed if the\n",
      "    original specification contained real equality. In this case, 'a'\n",
      "    requests axioms in which a separate substitutivity axiom is given for\n",
      "    each argument position of a function or predicate symbol, while 'A'\n",
      "    requests a single substitutivity axiom (covering all positions) for each\n",
      "    symbol. The short form or the long form without the optional argument is\n",
      "    equivalent to --print-saturated=eigEIG.\n",
      "\n",
      "  --print-sat-info\n",
      "    Print additional information (clause number, weight, etc) as a comment\n",
      "    for clauses from the semi-saturated end system.\n",
      "\n",
      "  --filter-saturated[=<arg>]\n",
      "    Filter the  (semi-) saturated clause sets after terminating the\n",
      "    saturation process. The argument is a string describing which operations\n",
      "    to take (and in which order). Options are 'u' (remove all clauses with\n",
      "    more than one literal), 'c' (delete all but one copy of identical\n",
      "    clauses, 'n', 'r', 'f' (forward contraction, unit-subsumption only, no\n",
      "    rewriting, rewriting with rules only, full rewriting, respectively), and\n",
      "    'N', 'R' and 'F' (as their lower case counterparts, but with\n",
      "    non-unit-subsumption enabled as well). The option without the optional\n",
      "    argument is equivalent to --filter-saturated=Fc.\n",
      "\n",
      "  --prune\n",
      "    Stop after relevancy pruning, SInE pruning, and output of the initial\n",
      "    clause- and formula set. This will automatically set output level to 4 so\n",
      "    that the pruned problem specification is printed. Note that the desired\n",
      "    pruning methods must still be specified (e.g. '--sine=Auto').\n",
      "\n",
      "  --cnf\n",
      "    Convert the input problem into clause normal form and print it. This is\n",
      "    (nearly) equivalent to '--print-saturated=eigEIG\n",
      "    --processed-clauses-limit=0' and will by default perform some usually\n",
      "    useful simplifications. You can additionally specify e.g.\n",
      "    '--no-preprocessing' if you want just the result of CNF translation.\n",
      "\n",
      "  --print-pid\n",
      "    Print the process id of the prover as a comment after option processing.\n",
      "\n",
      "  --print-version\n",
      "    Print the version number of the prover as a comment after option\n",
      "    processing. Note that unlike -version, the prover will not terminate, but\n",
      "    proceed normally.\n",
      "\n",
      "  --error-on-empty\n",
      "    Return with an error code if the input file contains no clauses.\n",
      "    Formally, the empty clause set (as an empty conjunction of clauses) is\n",
      "    trivially satisfiable, and E will treat any empty input set as\n",
      "    satisfiable. However, in composite systems this is more often a sign that\n",
      "    something went wrong. Use this option to catch such bugs.\n",
      "\n",
      "   -m <arg>\n",
      "  --memory-limit=<arg>\n",
      "    Limit the memory the prover may use. The argument is the allowed amount\n",
      "    of memory in MB. If you use the argument 'Auto', the system will try to\n",
      "    figure out the amount of physical memory of your machine and claim most\n",
      "    of it. This option may not work everywhere, due to broken and/or strange\n",
      "    behaviour of setrlimit() in some UNIX implementations, and due to the\n",
      "    fact that I know of no portable way to figure out the physical memory in\n",
      "    a machine. Both the option and the 'Auto' version do work under all\n",
      "    tested versions of Solaris and GNU/Linux. Due to problems with limit data\n",
      "    types, it is currently impossible to set a limit of more than 2 GB (2048\n",
      "    MB).\n",
      "\n",
      "  --cpu-limit[=<arg>]\n",
      "    Limit the cpu time the prover should run. The optional argument is the\n",
      "    CPU time in seconds. The prover will terminate immediately after reaching\n",
      "    the time limit, regardless of internal state. This option may not work\n",
      "    everywhere, due to broken and/or strange behaviour of setrlimit() in some\n",
      "    UNIX implementations. It does work under all tested versions of Solaris,\n",
      "    HP-UX, MacOS-X, and GNU/Linux. As a side effect, this option will inhibit\n",
      "    core file writing. Please note that if you use both --cpu-limit and\n",
      "    --soft-cpu-limit, the soft limit has to be smaller than the hard limit to\n",
      "    have any effect.  The option without the optional argument is equivalent\n",
      "    to --cpu-limit=300.\n",
      "\n",
      "  --soft-cpu-limit[=<arg>]\n",
      "    Limit the cpu time the prover should spend in the main saturation phase.\n",
      "    The prover will then terminate gracefully, i.e. it will perform\n",
      "    post-processing, filtering and printing of unprocessed clauses, if these\n",
      "    options are selected. Note that for some filtering options (in particular\n",
      "    those which perform full subsumption), the post-processing time may well\n",
      "    be larger than the saturation time. This option is particularly useful if\n",
      "    you want to use E as a preprocessor or lemma generator in a larger\n",
      "    system. The option without the optional argument is equivalent to\n",
      "    --soft-cpu-limit=290.\n",
      "\n",
      "   -R\n",
      "  --resources-info\n",
      "    Give some information about the resources used by the prover. You will\n",
      "    usually get CPU time information. On systems returning more information\n",
      "    with the rusage() system call, you will also get information about memory\n",
      "    consumption.\n",
      "\n",
      "   -C <arg>\n",
      "  --processed-clauses-limit=<arg>\n",
      "    Set the maximal number of clauses to process (i.e. the number of\n",
      "    traversals of the main-loop).\n",
      "\n",
      "   -P <arg>\n",
      "  --processed-set-limit=<arg>\n",
      "    Set the maximal size of the set of processed clauses. This differs from\n",
      "    the previous option in that redundant and back-simplified processed\n",
      "    clauses are not counted.\n",
      "\n",
      "   -U <arg>\n",
      "  --unprocessed-limit=<arg>\n",
      "    Set the maximal size of the set of unprocessed clauses. This is a\n",
      "    termination condition, not something to use to control the deletion of\n",
      "    bad clauses. Compare --delete-bad-limit.\n",
      "\n",
      "   -T <arg>\n",
      "  --total-clause-set-limit=<arg>\n",
      "    Set the maximal size of the set of all clauses. See previous option.\n",
      "\n",
      "  --generated-limit=<arg>\n",
      "    Set the maximal number of generated clauses before the proof search\n",
      "    stops. This is a reasonable (though not great) estimate of the work done.\n",
      "\n",
      "  --tb-insert-limit=<arg>\n",
      "    Set the maximal number of of term bank term top insertions. This is a\n",
      "    reasonable (though not great) estimate of the work done.\n",
      "\n",
      "  --answers[=<arg>]\n",
      "    Set the maximal number of answers to print for existentially quantified\n",
      "    questions. Without this option, the prover terminates after the first\n",
      "    answer found. If the value is different from 1, the prover is no longer\n",
      "    guaranteed to terminate, even if there is a finite number of answers. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --answers=2147483647.\n",
      "\n",
      "  --conjectures-are-questions\n",
      "    Treat all conjectures as questions to be answered. This is a wart\n",
      "    necessary because CASC-J6 has categories requiring answers, but does not\n",
      "    yet support the 'question' type for formulas.\n",
      "\n",
      "   -n\n",
      "  --eqn-no-infix\n",
      "    In LOP, print equations in prefix notation equal(x,y).\n",
      "\n",
      "   -e\n",
      "  --full-equational-rep\n",
      "    In LOP. print all literals as equations, even non-equational ones.\n",
      "\n",
      "  --lop-in\n",
      "    Set E-LOP as the input format. If no input format is selected by this or\n",
      "    one of the following options, E will guess the input format based on the\n",
      "    first token. It will almost always correctly recognize TPTP-3, but it may\n",
      "    misidentify E-LOP files that use TPTP meta-identifiers as logical\n",
      "    symbols.\n",
      "\n",
      "  --pcl-out\n",
      "    Set PCL as the proof object output format.\n",
      "\n",
      "  --tptp-in\n",
      "    Set TPTP-2 as the input format (but note that includes are still handled\n",
      "    according to TPTP-3 semantics).\n",
      "\n",
      "  --tptp-out\n",
      "    Print TPTP format instead of E-LOP. Implies --eqn-no-infix and will\n",
      "    ignore --full-equational-rep.\n",
      "\n",
      "  --tptp-format\n",
      "    Equivalent to --tptp-in and --tptp-out.\n",
      "\n",
      "  --tptp2-in\n",
      "    Synonymous with --tptp-in.\n",
      "\n",
      "  --tptp2-out\n",
      "    Synonymous with --tptp-out.\n",
      "\n",
      "  --tptp2-format\n",
      "    Synonymous with --tptp-format.\n",
      "\n",
      "  --tstp-in\n",
      "    Set TPTP-3 as the input format (Note that TPTP-3 syntax is still under\n",
      "    development, and the version in E may not be fully conforming at all\n",
      "    times. E works on all TPTP 6.3.0 FOF and CNF files (including includes).\n",
      "\n",
      "  --tstp-out\n",
      "    Print output clauses in TPTP-3 syntax. In particular, for output levels\n",
      "    >=2, write derivations as TPTP-3 derivations.\n",
      "\n",
      "  --tstp-format\n",
      "    Equivalent to --tstp-in and --tstp-out.\n",
      "\n",
      "  --tptp3-in\n",
      "    Synonymous with --tstp-in.\n",
      "\n",
      "  --tptp3-out\n",
      "    Synonymous with --tstp-out.\n",
      "\n",
      "  --tptp3-format\n",
      "    Synonymous with --tstp-format.\n",
      "\n",
      "  --auto\n",
      "    Automatically determine settings for proof search. This is equivalent to\n",
      "    -xAuto -tAuto --sine=Auto.\n",
      "\n",
      "  --satauto\n",
      "    Automatically determine settings for proof/saturation search. This is\n",
      "    equivalent to -xAuto -tAuto.\n",
      "\n",
      "  --autodev\n",
      "    Automatically determine settings for proof search (development version).\n",
      "    This is equivalent to -xAutoDev -tAutoDev --sine=Auto.\n",
      "\n",
      "  --satautodev\n",
      "    Automatically determine settings for proof/saturation search (development\n",
      "    version). This is equivalent to -xAutoDev -tAutoDev.\n",
      "\n",
      "  --auto-schedule\n",
      "    Use the (experimental) strategy scheduling. This will try several\n",
      "    different fully specified search strategies (aka \"Auto-Modes\"), one after\n",
      "    the other, until a proof or saturation is found, or the time limit is\n",
      "    exceeded.\n",
      "\n",
      "  --satauto-schedule\n",
      "    Use the (experimental) strategy scheduling without SInE, thus maintaining\n",
      "    completeness.\n",
      "\n",
      "  --no-preprocessing\n",
      "    Do not perform preprocessing on the initial clause set. Preprocessing\n",
      "    currently removes tautologies and orders terms, literals and clauses in a\n",
      "    certain (\"canonical\") way before anything else happens. Unless limited by\n",
      "    one of the following options, it will also unfold equational definitions.\n",
      "\n",
      "  --eq-unfold-limit=<arg>\n",
      "    During preprocessing, limit unfolding (and removing) of equational\n",
      "    definitions to those where the expanded definition is at most the given\n",
      "    limit bigger (in terms of standard weight) than the defined term.\n",
      "\n",
      "  --eq-unfold-maxclauses=<arg>\n",
      "    During preprocessing, don't try unfolding of equational definitions if\n",
      "    the problem has more than this limit of clauses.\n",
      "\n",
      "  --no-eq-unfolding\n",
      "    During preprocessing, abstain from unfolding (and removing) equational\n",
      "    definitions.\n",
      "\n",
      "  --sine[=<arg>]\n",
      "    Apply SInE to prune the unprocessed axioms with the specified filter.\n",
      "    'Auto' will automatically pick a filter. The option without the optional\n",
      "    argument is equivalent to --sine=Auto.\n",
      "\n",
      "  --rel-pruning-level[=<arg>]\n",
      "    Perform relevancy pruning up to the given level on the unprocessed\n",
      "    axioms. The option without the optional argument is equivalent to\n",
      "    --rel-pruning-level=3.\n",
      "\n",
      "  --presat-simplify\n",
      "    Before proper saturation do a complete interreduction of the proof state.\n",
      "\n",
      "  --ac-handling[=<arg>]\n",
      "    Select AC handling mode, i.e. determine what to do with redundant AC\n",
      "    tautologies. The default is equivalent to 'DiscardAll', the other\n",
      "    possible values are 'None' (to disable AC handling), 'KeepUnits', and\n",
      "    'KeepOrientable'. The option without the optional argument is equivalent\n",
      "    to --ac-handling=KeepUnits.\n",
      "\n",
      "  --ac-non-aggressive\n",
      "    Do AC resolution on negative literals only on processing (by default, AC\n",
      "    resolution is done after clause creation). Only effective if AC handling\n",
      "    is not disabled.\n",
      "\n",
      "   -W <arg>\n",
      "  --literal-selection-strategy=<arg>\n",
      "    Choose a strategy for selection of negative literals. There are two\n",
      "    special values for this option: NoSelection will select no literal (i.e.\n",
      "    perform normal superposition) and NoGeneration will inhibit all\n",
      "    generating inferences. For a list of the other (hopefully\n",
      "    self-documenting) values run 'eprover -W none'. There are two variants of\n",
      "    each strategy. The one prefixed with 'P' will allow paramodulation into\n",
      "    maximal positive literals in addition to paramodulation into maximal\n",
      "    selected negative literals.\n",
      "\n",
      "  --no-generation\n",
      "    Don't perform any generating inferences (equivalent to\n",
      "    --literal-selection-strategy=NoGeneration).\n",
      "\n",
      "  --select-on-processing-only\n",
      "    Perform literal selection at processing time only (i.e. select only in\n",
      "    the _given clause_), not before clause evaluation. This is relevant\n",
      "    because many clause selection heuristics give special consideration to\n",
      "    maximal or selected literals.\n",
      "\n",
      "   -i\n",
      "  --inherit-paramod-literals\n",
      "    Always select the negative literals a previous inference paramodulated\n",
      "    into (if possible). If no such literal exists, select as dictated by the\n",
      "    selection strategy.\n",
      "\n",
      "   -j\n",
      "  --inherit-goal-pm-literals\n",
      "    In a goal (all negative clause), always select the negative literals a\n",
      "    previous inference paramodulated into (if possible). If no such literal\n",
      "    exists, select as dictated by the selection strategy.\n",
      "\n",
      "  --inherit-conjecture-pm-literals\n",
      "    In a conjecture-derived clause, always select the negative literals a\n",
      "    previous inference paramodulated into (if possible). If no such literal\n",
      "    exists, select as dictated by the selection strategy.\n",
      "\n",
      "  --selection-pos-min=<arg>\n",
      "    Set a lower limit for the number of positive literals a clause must have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-pos-max=<arg>\n",
      "    Set a upper limit for the number of positive literals a clause can have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-neg-min=<arg>\n",
      "    Set a lower limit for the number of negative literals a clause must have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-neg-max=<arg>\n",
      "    Set a upper limit for the number of negative literals a clause can have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-all-min=<arg>\n",
      "    Set a lower limit for the number of literals a clause must have to be\n",
      "    eligible for literal selection.\n",
      "\n",
      "  --selection-all-max=<arg>\n",
      "    Set an upper limit for the number of literals a clause must have to be\n",
      "    eligible for literal selection.\n",
      "\n",
      "  --selection-weight-min=<arg>\n",
      "    Set the minimum weight a clause must have to be eligible for literal\n",
      "    selection.\n",
      "\n",
      "  --prefer-initial-clauses\n",
      "    Always process all initial clauses first.\n",
      "\n",
      "   -x <arg>\n",
      "  --expert-heuristic=<arg>\n",
      "    Select one of the clause selection heuristics. Currently at least\n",
      "    available: Auto, Weight, StandardWeight, RWeight, FIFO, LIFO, Uniq,\n",
      "    UseWatchlist. For a full list check HEURISTICS/che_proofcontrol.c. Auto\n",
      "    is recommended if you only want to find a proof. It is special in that it\n",
      "    will also set some additional options. To have optimal performance, you\n",
      "    also should specify -tAuto to select a good term ordering. LIFO is unfair\n",
      "    and will make the prover incomplete. Uniq is used internally and is not\n",
      "    very useful in most cases. You can define more heuristics using the\n",
      "    option -H (see below).\n",
      "\n",
      "  --filter-orphans-limit[=<arg>]\n",
      "    Orphans are unprocessed clauses where one of the parents has been removed\n",
      "    by back-simolification. They are redundant and usually removed lazily\n",
      "    (i.e. only when they are selected for processing). With this option you\n",
      "    can select a limit on back-simplified clauses  after which orphans will\n",
      "    be eagerly deleted. The option without the optional argument is\n",
      "    equivalent to --filter-orphans-limit=100.\n",
      "\n",
      "  --forward-contract-limit[=<arg>]\n",
      "    Set a limit on the number of processed clauses after which the\n",
      "    unprocessed clause set will be re-simplified and reweighted.  The option\n",
      "    without the optional argument is equivalent to\n",
      "    --forward-contract-limit=80000.\n",
      "\n",
      "  --delete-bad-limit[=<arg>]\n",
      "    Set the number of storage units after which bad clauses are deleted\n",
      "    without further consideration. This causes the prover to be potentially\n",
      "    incomplete, but will allow you to limit the maximum amount of memory used\n",
      "    fairly well. The prover will tell you if a proof attempt failed due to\n",
      "    the incompleteness introduced by this option. It is recommended to set\n",
      "    this limit significantly higher than --filter-limit or\n",
      "    --filter-copies-limit. If you select -xAuto and set a memory limit, the\n",
      "    prover will determine a good value automatically. The option without the\n",
      "    optional argument is equivalent to --delete-bad-limit=1500000.\n",
      "\n",
      "  --assume-completeness\n",
      "    There are various way (e.g. the next few options) to configure the prover\n",
      "    to be strongly incomplete in the general case. E will detect when such an\n",
      "    option is selected and return corresponding exit states (i.e. it will not\n",
      "    claim satisfiability just because it ran out of unprocessed clauses). If\n",
      "    you _know_ that for your class of problems the selected strategy is still\n",
      "    complete, use this option to tell the system that this is the case.\n",
      "\n",
      "  --assume-incompleteness\n",
      "    This option instructs the prover to assume incompleteness (typically\n",
      "    because the axiomatization already is incomplete because axioms have been\n",
      "    filtered before they are handed to the system.\n",
      "\n",
      "  --disable-eq-factoring\n",
      "    Disable equality factoring. This makes the prover incomplete for general\n",
      "    non-Horn problems, but helps for some specialized classes. It is not\n",
      "    necessary to disable equality factoring for Horn problems, as Horn\n",
      "    clauses are not factored anyways.\n",
      "\n",
      "  --disable-paramod-into-neg-units\n",
      "    Disable paramodulation into negative unit clause. This makes the prover\n",
      "    incomplete in the general case, but helps for some specialized classes.\n",
      "\n",
      "  --condense\n",
      "    Enable condensing for the given clause. Condensing replaces a clause by a\n",
      "    more general factor (if such a factor exists).\n",
      "\n",
      "  --condense-aggressive\n",
      "    Enable condensing for the given and newly generated clauses.\n",
      "\n",
      "  --disable-given-clause-fw-contraction\n",
      "    Disable simplification and subsumption of the newly selected given clause\n",
      "    (clauses are still simplified when they are generated). In general, this\n",
      "    breaks some basic assumptions of the DISCOUNT loop proof search\n",
      "    procedure. However, there are some problem classes in which  this\n",
      "    simplifications empirically never occurs. In such cases, we can save\n",
      "    significant overhead. The option _should_ work in all cases, but is not\n",
      "    expected to improve things in most cases.\n",
      "\n",
      "  --simul-paramod\n",
      "    Use simultaneous paramodulation to implement superposition. Default is to\n",
      "    use plain paramodulation.\n",
      "\n",
      "  --oriented-simul-paramod\n",
      "    Use simultaneous paramodulation for oriented from-literals. This is an\n",
      "    experimental feature.\n",
      "\n",
      "  --supersimul-paramod\n",
      "    Use supersimultaneous paramodulation to implement superposition. Default\n",
      "    is to use plain paramodulation.\n",
      "\n",
      "  --oriented-supersimul-paramod\n",
      "    Use supersimultaneous paramodulation for oriented from-literals. This is\n",
      "    an experimental feature.\n",
      "\n",
      "  --split-clauses[=<arg>]\n",
      "    Determine which clauses should be subject to splitting. The argument is\n",
      "    the binary 'OR' of values for the desired classes:\n",
      "         1:  Horn clauses\n",
      "         2:  Non-Horn clauses\n",
      "         4:  Negative clauses\n",
      "         8:  Positive clauses\n",
      "        16:  Clauses with both positive and negative literals\n",
      "    Each set bit adds that class to the set of clauses which will be split.\n",
      "    The option without the optional argument is equivalent to\n",
      "    --split-clauses=7.\n",
      "\n",
      "  --split-method=<arg>\n",
      "    Determine how to treat ground literals in splitting. The argument is\n",
      "    either '0' to denote no splitting of ground literals (they are all\n",
      "    assigned to the first split clause produced), '1' to denote that all\n",
      "    ground literals should form a single new clause, or '2', in which case\n",
      "    ground literals are treated as usual and are all split off into\n",
      "    individual clauses.\n",
      "\n",
      "  --split-aggressive\n",
      "    Apply splitting to new clauses (after simplification) and before\n",
      "    evaluation. By default, splitting (if activated) is only performed on\n",
      "    selected clauses. \n",
      "\n",
      "  --split-reuse-defs\n",
      "    If possible, reuse previous definitions for splitting.\n",
      "\n",
      "   -t <arg>\n",
      "  --term-ordering=<arg>\n",
      "    Select an ordering type (currently Auto, LPO, LPO4, KBO or KBO6). -tAuto\n",
      "    is suggested, in particular with -xAuto. KBO and KBO6 are different\n",
      "    implementations of the same ordering, KBO6 is usually faster and has had\n",
      "    more testing. Similarly, LPO4 is a new, equivalent but superior\n",
      "    implementation of LPO.\n",
      "\n",
      "   -w <arg>\n",
      "  --order-weight-generation=<arg>\n",
      "    Select a method for the generation of weights for use with the term\n",
      "    ordering. Run 'eprover -w none' for a list of options.\n",
      "\n",
      "  --order-weights=<arg>\n",
      "    Describe a (partial) assignments of weights to function symbols for term\n",
      "    orderings (in particular, KBO). You can specify a list of weights of the\n",
      "    form 'f1:w1,f2:w2, ...'. Since a total weight assignment is needed, E\n",
      "    will _first_ apply any weight generation scheme specified (or the default\n",
      "    one), and then modify the weights as specified. Note that E performs only\n",
      "    very basic sanity checks, so you probably can specify weights that break\n",
      "    KBO constraints.\n",
      "\n",
      "   -G <arg>\n",
      "  --order-precedence-generation=<arg>\n",
      "    Select a method for the generation of a precedence for use with the term\n",
      "    ordering. Run 'eprover -G none' for a list of options.\n",
      "\n",
      "  --prec-pure-conj[=<arg>]\n",
      "    Set a weight for symbols that occur in conjectures only to determinewhere\n",
      "    to place it in the precedence. This value is used for a roughpre-order,\n",
      "    the normal schemes only sort within symbols with the sameoccurance\n",
      "    modifier. The option without the optional argument is equivalent to\n",
      "    --prec-pure-conj=10.\n",
      "\n",
      "  --prec-conj-axiom[=<arg>]\n",
      "    Set a weight for symbols that occur in both conjectures and axiomsto\n",
      "    determine where to place it in the precedence. This value is used for a\n",
      "    rough pre-order, the normal schemes only sort within symbols with the\n",
      "    same occurance modifier. The option without the optional argument is\n",
      "    equivalent to --prec-conj-axiom=5.\n",
      "\n",
      "  --prec-pure-axiom[=<arg>]\n",
      "    Set a weight for symbols that occur in axioms only to determine where to\n",
      "    place it in the precedence. This value is used for a rough pre-order, the\n",
      "    normal schemes only sort within symbols with the same occurance modifier.\n",
      "    The option without the optional argument is equivalent to\n",
      "    --prec-pure-axiom=2.\n",
      "\n",
      "  --prec-skolem[=<arg>]\n",
      "    Set a weight for Skolem symbols to determine where to place it in the\n",
      "    precedence. This value is used for a rough pre-order, the normal schemes\n",
      "    only sort within symbols with the same occurance modifier. The option\n",
      "    without the optional argument is equivalent to --prec-skolem=2.\n",
      "\n",
      "  --prec-defpred[=<arg>]\n",
      "    Set a weight for introduced predicate symbols (usually via definitional\n",
      "    CNF or clause splitting) to determine where to place it in the\n",
      "    precedence. This value is used for a rough pre-order, the normal schemes\n",
      "    only sort within symbols with the same occurance modifier. The option\n",
      "    without the optional argument is equivalent to --prec-defpred=2.\n",
      "\n",
      "   -c <arg>\n",
      "  --order-constant-weight=<arg>\n",
      "    Set a special weight > 0 for constants in the term ordering. By default,\n",
      "    constants are treated like other function symbols.\n",
      "\n",
      "  --precedence[=<arg>]\n",
      "    Describe a (partial) precedence for the term ordering used for the proof\n",
      "    attempt. You can specify a comma-separated list of precedence chains,\n",
      "    where a precedence chain is a list of function symbols (which all have to\n",
      "    appear in the proof problem), connected by >, <, or =. If this option is\n",
      "    used in connection with --order-precedence-generation, the partial\n",
      "    ordering will be completed using the selected method, otherwise the\n",
      "    prover runs with a non-ground-total ordering. The option without the\n",
      "    optional argument is equivalent to --precedence=.\n",
      "\n",
      "  --lpo-recursion-limit[=<arg>]\n",
      "    Set a depth limit for LPO comparisons. Most comparisons do not need more\n",
      "    than 10 or 20 levels of recursion. By default, recursion depth is limited\n",
      "    to 1000 to avoid stack overflow problems. If the limit is reached, the\n",
      "    prover assumes that the terms are uncomparable. Smaller values make the\n",
      "    comparison attempts faster, but less exact. Larger values have the\n",
      "    opposite effect. Values up to 20000 should be save on most operating\n",
      "    systems. If you run into segmentation faults while using LPO or LPO4,\n",
      "    first try to set this limit to a reasonable value. If the problem\n",
      "    persists, send a bug report ;-) The option without the optional argument\n",
      "    is equivalent to --lpo-recursion-limit=100.\n",
      "\n",
      "  --restrict-literal-comparisons\n",
      "    Make all literals uncomparable in the term ordering (i.e. do not use the\n",
      "    term ordering to restrict paramodulation, equality resolution and\n",
      "    factoring to certain literals. This is necessary to make\n",
      "    Set-of-Support-strategies complete for the non-equational case (It still\n",
      "    is incomplete for the equational case, but pretty useless anyways).\n",
      "\n",
      "  --literal-comparison=<arg>\n",
      "    Modify how literal comparisons are done. 'None' is equivalent to the\n",
      "    previous option, 'Normal' uses the normal lifting of the term ordering,\n",
      "    'TFOEqMax' uses the equivalent of a transfinite ordering deciding on the\n",
      "    predicate symbol and making equational literals maximal, and 'TFOEqMin'\n",
      "    modifies this by making equational symbols minimal.\n",
      "\n",
      "  --sos-uses-input-types\n",
      "    If input is TPTP format, use TPTP conjectures for initializing the Set of\n",
      "    Support. If not in TPTP format, use E-LOP queries (clauses of the form\n",
      "    ?-l(X),...,m(Y)). Normally, all negative clauses are used. Please note\n",
      "    that most E heuristics do not use this information at all, it is\n",
      "    currently only useful for certain parameter settings (including the\n",
      "    SimulateSOS priority function).\n",
      "\n",
      "  --destructive-er\n",
      "    Allow destructive equality resolution inferences on pure-variable\n",
      "    literals of the form X!=Y, i.e. replace the original clause with the\n",
      "    result of an equality resolution inference on this literal.\n",
      "\n",
      "  --strong-destructive-er\n",
      "    Allow destructive equality resolution inferences on literals of the form\n",
      "    X!=t (where X does not occur in t), i.e. replace the original clause with\n",
      "    the result of an equality resolution inference on this literal. Unless I\n",
      "    am brain-dead, this maintains completeness, although the proof is rather\n",
      "    tricky.\n",
      "\n",
      "  --destructive-er-aggressive\n",
      "    Apply destructive equality resolution to all newly generated clauses, not\n",
      "    just to selected clauses. Implies --destructive-er.\n",
      "\n",
      "  --forward-context-sr\n",
      "    Apply contextual simplify-reflect with processed clauses to the given\n",
      "    clause.\n",
      "\n",
      "  --forward-context-sr-aggressive\n",
      "    Apply contextual simplify-reflect with processed clauses to new clauses.\n",
      "    Implies --forward-context-sr.\n",
      "\n",
      "  --backward-context-sr\n",
      "    Apply contextual simplify-reflect with the given clause to processed\n",
      "    clauses.\n",
      "\n",
      "   -g\n",
      "  --prefer-general-demodulators\n",
      "    Prefer general demodulators. By default, E prefers specialized\n",
      "    demodulators. This affects in which order the rewrite  index is\n",
      "    traversed.\n",
      "\n",
      "   -F <arg>\n",
      "  --forward-demod-level=<arg>\n",
      "    Set the desired level for rewriting of unprocessed clauses. A value of 0\n",
      "    means no rewriting, 1 indicates to use rules (orientable equations) only,\n",
      "    2 indicates full rewriting with rules and instances of unorientable\n",
      "    equations. Default behavior is 2.\n",
      "\n",
      "  --strong-rw-inst\n",
      "    Instantiate unbound variables in matching potential demodulators with a\n",
      "    small constant terms.\n",
      "\n",
      "   -u\n",
      "  --strong-forward-subsumption\n",
      "    Try multiple positions and unit-equations to try to equationally subsume\n",
      "    a single new clause. Default is to search for a single position.\n",
      "\n",
      "  --satcheck-proc-interval[=<arg>]\n",
      "    Enable periodic SAT checking at the given interval of main loop\n",
      "    non-trivial processed clauses. The option without the optional argument\n",
      "    is equivalent to --satcheck-proc-interval=5000.\n",
      "\n",
      "  --satcheck-gen-interval[=<arg>]\n",
      "    Enable periodic SAT checking whenever the total proof state size\n",
      "    increases by the given limit. The option without the optional argument is\n",
      "    equivalent to --satcheck-gen-interval=10000.\n",
      "\n",
      "  --satcheck-ttinsert-interval[=<arg>]\n",
      "    Enable periodic SAT checking whenever the number of term tops insertions\n",
      "    matches the given limit (which grows exponentially). The option without\n",
      "    the optional argument is equivalent to\n",
      "    --satcheck-ttinsert-interval=5000000.\n",
      "\n",
      "  --satcheck[=<arg>]\n",
      "    Set the grounding strategy for periodic SAT checking. Note that to enable\n",
      "    SAT checking, it is also necessary to set the interval with one of the\n",
      "    previous two options. The option without the optional argument is\n",
      "    equivalent to --satcheck=FirstConst.\n",
      "\n",
      "  --satcheck-decision-limit[=<arg>]\n",
      "    Set the number of decisions allowed for each run of the SAT solver. If\n",
      "    the option is not given, the built-in value is 10000. Use -1 to allow\n",
      "    unlimited decision. The option without the optional argument is\n",
      "    equivalent to --satcheck-decision-limit=100.\n",
      "\n",
      "  --satcheck-normalize-const\n",
      "    Use the current normal form (as recorded in the termbank rewrite cache)\n",
      "    of the selected constant as the term for the grounding substitution.\n",
      "\n",
      "  --satcheck-normalize-unproc\n",
      "    Enable re-simplification (heuristic re-revaluation) of unprocessed\n",
      "    clauses before grounding for SAT checking.\n",
      "\n",
      "  --watchlist[=<arg>]\n",
      "    Give the name for a file containing clauses to be watched for during the\n",
      "    saturation process. If a clause is generated that subsumes a watchlist\n",
      "    clause, the subsumed clause is removed from the watchlist. The prover\n",
      "    will terminate when the watchlist is empty. If you want to use the\n",
      "    watchlist for guiding the proof, put the empty clause onto the list and\n",
      "    use the built-in clause selection heuristic 'UseWatchlist' (or build a\n",
      "    heuristic yourself using the priority functions 'PreferWatchlist' and\n",
      "    'DeferWatchlist'). Use the argument 'Use inline watchlist type' (or no\n",
      "    argument) and the special clause type 'watchlist' if you want to put\n",
      "    watchlist clauses into the normal input stream. This is only supported\n",
      "    for TPTP input formats. The option without the optional argument is\n",
      "    equivalent to --watchlist='Use inline watchlist type'.\n",
      "\n",
      "  --static-watchlist[=<arg>]\n",
      "    This is identical to the previous option, but subsumed clauses willnot be\n",
      "    removed from the watchlist (and hence the prover will not terminate if\n",
      "    all watchlist clauses have been subsumed. This may be more useful for\n",
      "    heuristic guidance. The option without the optional argument is\n",
      "    equivalent to --static-watchlist='Use inline watchlist type'.\n",
      "\n",
      "  --no-watchlist-simplification\n",
      "    By default, the watchlist is brought into normal form with respect to the\n",
      "    current processed clause set and certain simplifications. This option\n",
      "    disables simplification for the watchlist.\n",
      "\n",
      "  --conventional-subsumption\n",
      "    Equivalent to --subsumption-indexing=None.\n",
      "\n",
      "  --subsumption-indexing=<arg>\n",
      "    Determine choice of indexing for (most) subsumption operations. Choices\n",
      "    are 'None' for naive subsumption, 'Direct' for direct mapped FV-Indexing,\n",
      "    'Perm' for permuted FV-Indexing and 'PermOpt' for permuted FV-Indexing\n",
      "    with deletion of (suspected) non-informative features. Default behaviour\n",
      "    is 'Perm'.\n",
      "\n",
      "  --fvindex-featuretypes=<arg>\n",
      "    Select the feature types used for indexing. Choices are \"None\" to disable\n",
      "    FV-indexing, \"AC\" for AC compatible features (the default) (literal\n",
      "    number and symbol counts), \"SS\" for set subsumption compatible features\n",
      "    (symbol depth), and \"All\" for all features.Unless you want to measure the\n",
      "    effects of the different features, I suggest you stick with the default.\n",
      "\n",
      "  --fvindex-maxfeatures[=<arg>]\n",
      "    Set the maximum initial number of symbols for feature computation.\n",
      "    Depending on the feature selection, a value of X here will convert into\n",
      "    2X+2 features (for set subsumption features), 2X+4 features (for\n",
      "    AC-compatible features) or 4X+6 features (if all features are used, the\n",
      "    default). Note that the actually used set of features may be smaller than\n",
      "    this if the signature does not contain enough symbols.For the Perm and\n",
      "    PermOpt version, this is _also_ used to set the maximum depth of the\n",
      "    feature vector index. Yes, I should probably make this into two separate\n",
      "    options. If you select a small value here, you should probably not use\n",
      "    \"Direct\" for the --subsumption-indexing option. The option without the\n",
      "    optional argument is equivalent to --fvindex-maxfeatures=200.\n",
      "\n",
      "  --fvindex-slack[=<arg>]\n",
      "    Set the number of slots reserved in the index for function symbols that\n",
      "    may be introduced into the signature later, e.g. by splitting. If no new\n",
      "    symbols are introduced, this just wastes time and memory. If PermOpt is\n",
      "    chosen, the slackness slots will be deleted from the index anyways, but\n",
      "    will still waste (a little) time in computing feature vectors. The option\n",
      "    without the optional argument is equivalent to --fvindex-slack=0.\n",
      "\n",
      "  --rw-bw-index[=<arg>]\n",
      "    Select fingerprint function for backwards rewrite index. \"NoIndex\" will\n",
      "    disable paramodulation indexing. For a list of the other values run\n",
      "    'eprover --pm-index=none'. FPX functions will use a fingerprint of X\n",
      "    positions, the letters disambiguate between different fingerprints with\n",
      "    the same sample size. The option without the optional argument is\n",
      "    equivalent to --rw-bw-index=FP7.\n",
      "\n",
      "  --pm-from-index[=<arg>]\n",
      "    Select fingerprint function for the index for paramodulation from indexed\n",
      "    clauses. \"NoIndex\" will disable paramodulation indexing. For a list of\n",
      "    the other values run 'eprover --pm-index=none'. FPX functionswill use a\n",
      "    fingerprint of X positions, the letters disambiguate between different\n",
      "    fingerprints with the same sample size. The option without the optional\n",
      "    argument is equivalent to --pm-from-index=FP7.\n",
      "\n",
      "  --pm-into-index[=<arg>]\n",
      "    Select fingerprint function for the index for paramodulation into the\n",
      "    indexed clauses. \"NoIndex\" will disable paramodulation indexing. For a\n",
      "    list of the other values run 'eprover --pm-index=none'. FPX functionswill\n",
      "    use a fingerprint of X positions, the letters disambiguate between\n",
      "    different fingerprints with the same sample size. The option without the\n",
      "    optional argument is equivalent to --pm-into-index=FP7.\n",
      "\n",
      "  --fp-index[=<arg>]\n",
      "    Select fingerprint function for all fingerprint indices. See above. The\n",
      "    option without the optional argument is equivalent to --fp-index=FP7.\n",
      "\n",
      "  --fp-no-size-constr\n",
      "    Disable usage of size constraints for matching with fingerprint indexing.\n",
      "\n",
      "  --pdt-no-size-constr\n",
      "    Disable usage of size constraints for matching with perfect\n",
      "    discrimination trees indexing.\n",
      "\n",
      "  --pdt-no-age-constr\n",
      "    Disable usage of age constraints for matching with perfect discrimination\n",
      "    trees indexing.\n",
      "\n",
      "  --detsort-rw\n",
      "    Sort set of clauses eliminated by backward rewriting using a total\n",
      "    syntactic ordering.\n",
      "\n",
      "  --detsort-new\n",
      "    Sort set of newly generated and backward simplified clauses using a total\n",
      "    syntactic ordering.\n",
      "\n",
      "   -D <arg>\n",
      "  --define-weight-function=<arg>\n",
      "    Define  a weight function (see manual for details). Later definitions\n",
      "    override previous definitions.\n",
      "\n",
      "   -H <arg>\n",
      "  --define-heuristic=<arg>\n",
      "    Define a clause selection heuristic (see manual for details). Later\n",
      "    definitions override previous definitions.\n",
      "\n",
      "  --free-numbers\n",
      "    Treat numbers (strings of decimal digits) as normal free function symbols\n",
      "    in the input. By default, number now are supposed to denote domain\n",
      "    constants and to be implicitly different from each other.\n",
      "\n",
      "  --free-objects\n",
      "    Treat object identifiers (strings in double quotes) as normal free\n",
      "    function symbols in the input. By default, object identifiers now\n",
      "    represent domain objects and are implicitly different from each other\n",
      "    (and from numbers, unless those are declared to be free).\n",
      "\n",
      "  --definitional-cnf[=<arg>]\n",
      "    Tune the clausification algorithm to introduces definitions for\n",
      "    subformulae to avoid exponential blow-up. The optional argument is a\n",
      "    fudge factor that determines when definitions are introduced. 0 disables\n",
      "    definitions completely. The default works well. The option without the\n",
      "    optional argument is equivalent to --definitional-cnf=24.\n",
      "\n",
      "  --old-cnf[=<arg>]\n",
      "    As the previous option, but use the classical, well-tested clausification\n",
      "    algorithm as opposed to the newewst one which avoides some algorithmic\n",
      "    pitfalls and hence works better on some exotic formulae. The two may\n",
      "    produce slightly different (but equisatisfiable) clause normal forms. The\n",
      "    option without the optional argument is equivalent to --old-cnf=24.\n",
      "\n",
      "  --miniscope-limit[=<arg>]\n",
      "    Set the limit of sub-formula-size to miniscope. The build-indefault is\n",
      "    256. Only applies to the new (default) clausification algorithm The\n",
      "    option without the optional argument is equivalent to\n",
      "    --miniscope-limit=2147483648.\n",
      "\n",
      "  --print-types\n",
      "    Print the type of every term. Useful for debugging purposes.\n",
      "\n",
      "  --app-encode\n",
      "    Encodes terms in the proof state using applicative encoding, prints\n",
      "    encoded input problem and exits.\n",
      "\n",
      "\n",
      "\n",
      "Copyright 1998-2020 by Stephan Schulz, schulz@eprover.org,\n",
      "and the E contributors (see DOC/CONTRIBUTORS).\n",
      "\n",
      "This program is a part of the distribution of the equational theorem\n",
      "prover E. You can find the latest version of the E distribution\n",
      "as well as additional information at\n",
      "http://www.eprover.org\n",
      "\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either version 2 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "This program is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program (it should be contained in the top level\n",
      "directory of the distribution in the file COPYING); if not, write to\n",
      "the Free Software Foundation, Inc., 59 Temple Place, Suite 330,\n",
      "Boston, MA  02111-1307 USA\n",
      "\n",
      "The original copyright holder can be contacted via email or as\n",
      "\n",
      "Stephan Schulz\n",
      "DHBW Stuttgart\n",
      "Fakultaet Technik\n",
      "Informatik\n",
      "Rotebuehlplatz 41\n",
      "70178 Stuttgart\n",
      "Germany\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = read(`eprover`, String))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "struct Sym\n",
    "    name::Symbol\n",
    "end\n",
    "\n",
    "struct Term\n",
    "    f::Symbol\n",
    "    arguments::Array{Any} # Array{Union{Term,Sym}}\n",
    "end\n",
    "\n",
    "\n",
    "struct ForAll\n",
    "    vars::Vec{Sym}\n",
    "    body\n",
    "end\n",
    "\n",
    "struct Exists\n",
    "    vars::Vec{Sym}\n",
    "    body\n",
    "end\n",
    "\n",
    "struct And\n",
    "    arguments::Vec{Any}\n",
    "end\n",
    "\n",
    "struct Or\n",
    "    arguments::Vec{Any}\n",
    "end\n",
    "\n",
    "struct Not\n",
    "    body\n",
    "end\n",
    "\n",
    "struct Eq\n",
    "    left\n",
    "    right\n",
    "end\n",
    "\n",
    "struct Implies\n",
    "    hyp\n",
    "    conc\n",
    "end\n",
    "\n",
    "struct Equiv\n",
    "    left\n",
    "    right\n",
    "end\n",
    "\n",
    "\n",
    "tptp( x::Not  ) = \"( ~ $(tptp(x.body)) )\"\n",
    "tptp( x::Eq  ) = \"( $(tptp(x.left)) = $(tptp(x.right)) )\"\n",
    "tptp( x ::ForAll ) = \"( ! [  $(join(map(tptp,x.vars),\" , \"))  ] :  $(tptp(x.body)) )\"\n",
    "tptp( x ::Exists ) = \"( ? [  $(join(map(tptp,x.vars),\" , \"))  ] :  $(tptp(x.body)) )\"\n",
    "tptp( x ::And ) = \"( $(join(map(tptp,x.vars),\" & \")) )\"\n",
    "tptp( x ::Or ) = \"( $(join(map(tptp,x.vars),\" | \")) )\"\n",
    "\n",
    "\n",
    "#=\n",
    "\\neg\n",
    "¬\n",
    "∧ \\wedge \\v \\vee\n",
    "\n",
    "∀\n",
    "∃\n",
    "=#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 3 7\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" $(1 + 2) $(3 + 4)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"( 1&2&3 )\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"( $(join(map(string,[1 2 3]),\"&\")) )\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"x  y\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string(\"x \" ,\" y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{Any}((3,))\n",
      "    1: Symbol ∧\n",
      "    2: Expr\n",
      "      head: Symbol call\n",
      "      args: Array{Any}((3,))\n",
      "        1: Symbol ∧\n",
      "        2: Symbol a\n",
      "        3: Symbol b\n",
      "    3: Symbol c\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid identifier name \"?\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid identifier name \"?\"",
      ""
     ]
    }
   ],
   "source": [
    "dump(:(a ∧ b ∧ c))\n",
    "dump(:( ? [x]  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.tptp.org/cgi-bin/SeeTPTP?Category=Problems&Domain=PUZ&File=PUZ131_1.p\n",
    "\n",
    "\n",
    "\n",
    "tff(student_type,type,(\n",
    "    student: $tType )).\n",
    "\n",
    "tff(professor_type,type,(\n",
    "    professor: $tType )).\n",
    "\n",
    "tff(course_type,type,(\n",
    "    course: $tType )).\n",
    "\n",
    "tff(michael_type,type,(\n",
    "    michael: student )).\n",
    "\n",
    "tff(victor_type,type,(\n",
    "    victor: professor )).\n",
    "\n",
    "tff(csc410_type,type,(\n",
    "    csc410: course )).\n",
    "\n",
    "tff(enrolled_type,type,(\n",
    "    enrolled: ( student * course ) > $o )).\n",
    "\n",
    "tff(teaches_type,type,(\n",
    "    teaches: ( professor * course ) > $o )).\n",
    "\n",
    "tff(taught_by_type,type,(\n",
    "    taughtby: ( student * professor ) > $o )).\n",
    "\n",
    "tff(coordinator_of_type,type,(\n",
    "    coordinatorof: course > professor )).\n",
    "\n",
    "tff(student_enrolled_axiom,axiom,(\n",
    "    ! [X: student] :\n",
    "    ? [Y: course] : enrolled(X,Y) )).\n",
    "\n",
    "tff(professor_teaches,axiom,(\n",
    "    ! [X: professor] :\n",
    "    ? [Y: course] : teaches(X,Y) )).\n",
    "\n",
    "tff(course_enrolled,axiom,(\n",
    "    ! [X: course] :\n",
    "    ? [Y: student] : enrolled(Y,X) )).\n",
    "\n",
    "tff(course_teaches,axiom,(\n",
    "    ! [X: course] :\n",
    "    ? [Y: professor] : teaches(Y,X) )).\n",
    "\n",
    "tff(coordinator_teaches,axiom,(\n",
    "    ! [X: course] : teaches(coordinatorof(X),X) )).\n",
    "\n",
    "tff(student_enrolled_taught,axiom,(\n",
    "    ! [X: student,Y: course] :\n",
    "      ( enrolled(X,Y)\n",
    "     => ! [Z: professor] :\n",
    "          ( teaches(Z,Y)\n",
    "         => taughtby(X,Z) ) ) )).\n",
    "\n",
    "tff(michael_enrolled_csc410_axiom,axiom,(\n",
    "    enrolled(michael,csc410) )).\n",
    "\n",
    "tff(victor_coordinator_csc410_axiom,axiom,(\n",
    "    coordinatorof(csc410) = victor )).\n",
    "\n",
    "tff(teaching_conjecture,conjecture,(\n",
    "    taughtby(michael,victor) )).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
