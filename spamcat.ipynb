{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z3 metalevle monomorphization.\n",
    "\n",
    "A thing that gave me pause was getting reasoning to be type correct. You needed typing guards.\n",
    "\n",
    "There are many approiaches to generics:\n",
    "dynamic typing with tags\n",
    "special mechanisms\n",
    "monorpmorphization\n",
    "\n",
    "(checkout that one rust review)\n",
    "\n",
    "Spiritually, the predciates are \n",
    "[Sort] -> Z3_expr\n",
    "we use python generators instead of list. with fair interleaving but maybe I shouldn't do that right now.\n",
    "\n",
    "\n",
    "Another big problem is actually how to input conditions\n",
    "\n",
    "There is a big difference between positive and negative uses of quantifiers.\n",
    "Left and right sequent rules.\n",
    "(forall o )  |- \n",
    "\n",
    "\n",
    "Any finite instantiation of the hyps quantifier is weaker than the actual notion and is acceptable.\n",
    "But only proving a finite instyati9on of the right is not acceptable.\n",
    "\n",
    "classically:\n",
    "|- forall a, P.\n",
    "|- not exists not P\n",
    "\n",
    "\n",
    "However excplitlity enumerasting \n",
    "|- p A \\/ pB \\/ p C \\/ p D is stronger than\n",
    "|- exists a, P\n",
    "\n",
    " |- not forall not P\n",
    " forall not P |- bot\n",
    "\n",
    "\n",
    "prove( hyps : Sort -> z3_bool, conc : z3_bool ):\n",
    "    s = Solver()\n",
    "    s.add(Not(conc))\n",
    "    # loop adding in sorts here.\n",
    "\n",
    "\n",
    "Horn clause + equality is sufficient \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyForAll():\n",
    "    \n",
    "\n",
    "class Sequent():\n",
    "    def __init__():\n",
    "    def given()\n",
    "    def require():\n",
    "    def add_hyp():\n",
    "    def add_conc():\n",
    "    def prove(self):\n",
    "        sort\n",
    "        [self.conc]\n",
    "        \n",
    "# object polymorphic functions\n",
    "def hom(f):\n",
    "    return json.dumps(f.type())\n",
    "\n",
    "def comp(f,g):\n",
    "    homf = f.type()\n",
    "    homg = g.type()\n",
    "    assert homf[\"dom\"] == homg[\"cod\"]\n",
    "    homfg = Hom(f.dom, g.cod)\n",
    "    comp = Function(\"comp\", honf, homg, homfg)\n",
    "    return comp(f,g)\n",
    "\n",
    "def id(obj):\n",
    "    hom = Hom(obj,obj)\n",
    "    return Const(\"id\", hom)\n",
    "\n",
    "\n",
    "\n",
    "# a particular instance of a pullback\n",
    "class PullBack():\n",
    "    def __init__(self, f, g, b, c, d):\n",
    "        \n",
    "fresh = 0\n",
    "def pullback(f, g, b, c, d):\n",
    "    # \n",
    "    fresh += 1\n",
    "    a = f\"obj_{fresh}\" # what if pullback IS an already known object. We can't assert equalities over objects? Hmm. This is a big limitation.\n",
    "    t1 = Hom(a,b)\n",
    "    t2 = Hom(b,c)\n",
    "    axioms = [\n",
    "        comp(p,f) == comp(q,g),\n",
    "        forallObj( lambda x: ForAll([p1,q1], Implies( tricommute, tricommute , squarecommute    ) )\n",
    "    ]\n",
    "    return a, p, q, axioms\n",
    "    \n",
    "\n",
    "# pullback predicate??? No way.\n",
    "def pullback(p,q,f,g):\n",
    "    homf = \n",
    "    homg = \n",
    "    \n",
    "def assert_has_pullbacks(C):\n",
    "def require_has_pullbacks(C):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7755fcea4f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mfred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a b c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mfred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7755fcea4f24>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, *typs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def Var():\n",
    "\n",
    "@dataclass\n",
    "class Var:\n",
    "    name:str\n",
    "\n",
    "@dataclass\n",
    "class Head:\n",
    "\n",
    "class Body():\n",
    "    def __init__(self, clauses):\n",
    "        self.clauses = clauses\n",
    "\n",
    "class Clause():\n",
    "\n",
    "'''\n",
    "\n",
    "class Clause():\n",
    "    def __init__(self, head, body):\n",
    "        self.head = head\n",
    "        self.body = body\n",
    "    def __and__(self,rhs):\n",
    "        if isinstance(rhs, Prop):\n",
    "            return Clause( self.head, self.body + [rhs]  )\n",
    "        elif isinstance(rhs, Clause):\n",
    "            assert rhs.head == None\n",
    "            return Clause( self.head , self.body + rhs.body )\n",
    "        assert False\n",
    "    def __lshift__(self,rhs):\n",
    "        if isinstance(rhs, Prop):\n",
    "            assert self.body == []\n",
    "            return Clause( self.head, [rhs]  )\n",
    "        elif isinstance(rhs, Clause):\n",
    "            assert rhs.head == None\n",
    "            return Clause( self.head , self.body + rhs.body )\n",
    "        assert False\n",
    "    def __repr__(self):\n",
    "        if len(self.body) == 0:\n",
    "            return f\"{repr(self.head)}.\"\n",
    "        else:\n",
    "            bodystr = \",\".join(map(repr,self.body))\n",
    "            return f\"{repr(self.head)} :- {bodystr}.\"\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "class Prop():\n",
    "    def __init__(self, rel, *args):\n",
    "        self.rel = rel\n",
    "        self.args = args\n",
    "    def lift_head(self):\n",
    "        return Clause(self, [])\n",
    "    def lift_body(self):\n",
    "        return Clause(None, [self])\n",
    "    def __and__(self, rhs):\n",
    "        return self.lift_body() & rhs\n",
    "    def __lshift__(self, rhs):\n",
    "        return self.lift_head() << rhs\n",
    "    def __repr__(self):\n",
    "        argstr = \",\".join(map(str,self.args))\n",
    "        return f\"{self.rel.name}({argstr})\"\n",
    "    \n",
    "   # def __repr__(self):\n",
    "   #     return f\"{self.head} :- {self.body}.\"\n",
    "\n",
    "\n",
    "    \n",
    "class Relation():\n",
    "    def __init__(self, name, *typs):\n",
    "        self.name = name\n",
    "        self.typs = typs\n",
    "        self.df = pd.DataFrame(columns=range(len(typs)))\n",
    "    def __call__(self, *args):\n",
    "        return Prop(self, *args)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#def datalog(clause):\n",
    "class Var():\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    def flatten(self):\n",
    "        return self\n",
    "\n",
    "def Vars(s):\n",
    "    return map(Var, s.split())\n",
    "    \n",
    "fred = Relation(\"fred\", [1,2,3])\n",
    "a,b,c = Vars(\"a b c\")\n",
    "fred(1,2,3)\n",
    "fred(a,b,c) << fred(a,a,a) & fred(b,b,b)\n",
    "#fred(a,b,c) << fred(a,a,a) << fred(b,b,b)\n",
    "\n",
    "\n",
    "class Term():\n",
    "    def __init__(self, name, *args):\n",
    "        self.head = name\n",
    "        self.args = args\n",
    "    def __eq__(self,rhs):\n",
    "        ind1, c1 = self.flatten()\n",
    "        ind2, c2 = rhs.flatten()\n",
    "        return Relation(\"equiv\", ind1, ind2), c1 & c2 \n",
    "    def flatten(self):    \n",
    "        res, clause = zip( [a.flatten() for a in args]   )\n",
    "        a = freshvar()\n",
    "        return a, Relation(self.name, a, *res) & clause\n",
    "def Fun(name):\n",
    "    return lambda *args: Term(name,*args)\n",
    "def Funs(s):\n",
    "    return map(Fun, s.split())\n",
    "\n",
    "    #def __call__(self, *args):\n",
    "    #    return Term(self.args = args\n",
    "        \n",
    "# a different equivalence class per type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this all beside the point ecept for just being fun and for finally having a system I can experiment with\n",
    "\n",
    "The point is that maybe I could encode also the pullback problem as guarded rewrite rules\n",
    "guarded egraph writing is like a horn clause. the egraph is the database\n",
    "\n",
    "If triangle commutes, if square commutes, then such and such exists and is unique\n",
    "Does seem encodable to egraph reasonign.\n",
    "\n",
    "\n",
    "square(a,b,c,d,f,g,h,k) :-\n",
    "pullback(f,g,)\n",
    "\n",
    "pullback(b,c,d,f,g) = (a, p1, p2) s.t.\n",
    "we have square.\n",
    "and for any object o with square, we have morphism triangles,\n",
    "and for any object o with square and triangles we have uniqueness\n",
    "\n",
    "\n",
    "given facts become rules.\n",
    "least fixed point semantics guarantees I stay well typed.\n",
    "forall O Q1 Q2,  \n",
    "% trianlge1      square            \n",
    "u(O) . p1 = Q1  :- Q1 . f = Q2 . g,, typ(Q1) = hom(O,_). % or check all the types? Deleting these is an optimization. Should put \n",
    "u(O) . p2 = Q2  :- Q1 . f = Q2 . g.\n",
    "% uniqueness\n",
    "E = u(O) :- E . p2 = Q2,  E . p1 = Q1 ,  Q1 . f = Q2 . g.\n",
    "\n",
    "\n",
    "hom(F,A,B).\n",
    "typ(Q1, hom(A,B)).\n",
    "\n",
    "\n",
    "to prove a such and such is pullback\n",
    "forall O, exists u, typ(u) = hom(O,)) =>  forall q1 q2, sqaure(q1, q2) & trianglw(q1, q2) =>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "% would direct axiomatization of equality even be so bad?\n",
    "a = b :- b = a.\n",
    "a = c :- a = b, b = c.\n",
    "a = a.\n",
    "\n",
    "\n",
    "\n",
    "consequences become queries?\n",
    "harrop formula?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I can merge pattern finding and equality propagation?\n",
    "\n",
    "instantiation too maybe?\n",
    "compression - remove unneeded eclass labels. They really pollute \n",
    "\n",
    "\n",
    "So there are two questions:\n",
    "What is the input language.\n",
    "The big difference between horn clause and the egraph is that we need to pick when to instantiate, when to insert.\n",
    "\n",
    "equiv(X,Y) is the analog of an eclass expansion step. We maintain enodes at the same id forever, but \n",
    "\n",
    "Rule versus start off the egraph. In datalog it is the same too.\n",
    "f(x,a,p) = g(r,q,w) :- .\n",
    "\n",
    "There is no way to express reuse id if this term already exists, or generate a new one if not. dollarsign is close but not cigar\n",
    "\n",
    "equiv() :- enode(Head, []), equiv()  right. we need multiarity then. We can compile to binary only if that helps. That also may let us curry?\n",
    "\n",
    "\n",
    "f(X) = g(X).\n",
    "turns into 3 rules\n",
    "a = b :- a ~ g(X), f(X) ~ $B.\n",
    "A = B :- A ~ g(X), f(X) ~ B. % this can happen in datalog\n",
    "A = B :- $A ~ g(X), f(X) ~ B. % these need to happen outside\n",
    "\n",
    "multirules\n",
    "\n",
    "compile directly to the egraph VM?\n",
    "\n",
    "Bind(\"f\", a,b,c), Check\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hmm. For the query you want to put it into the ergaph with no equalities. That kicks off the ematching\n",
    "\n",
    "\n",
    "datalog itself is a syntax for the ematching VM. It may be slightly higher level\n",
    "looking into a symbol table is binding variables\n",
    "looking into the equiavaence table is Bind\n",
    "Yield is rhs of datalog rule\n",
    "Check happens implicitly\n",
    "\n",
    "suggested notation:\n",
    "\n",
    "f(x) <- g(y) :- yada yada -- \n",
    "f(x) -> g(y) :- yada yada -- \n",
    "f(x) = g(y)  :- yada yada  -- bidirectional rule\n",
    "a ~ f(x) for eclass id dereferencing?\n",
    "\n",
    "could I use forall and exists to express gensym syntactically?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "What about this idea\n",
    "Put the rules in the egraph part. They find terms that can be equated. But never generate them\n",
    "Then the whole thing has to be run by a term generator, which may or may not be based on what is in the egraph or not.\n",
    "\n",
    "equiv(a,b) :- lhs_flat() , rhs_flat(). \n",
    "\n",
    "\n",
    "def equal(lhs,rhs):\n",
    "    tid1, lflat = lhs.flatten()\n",
    "    tid2, rflat = rhs.flatten()\n",
    "    return Term(\"equal\", tid1, tid2), lflat + rflat\n",
    "\n",
    "% this would generate a new term f(A,B,newsym)\n",
    "% but not do anything with it. \n",
    "f_new(A,B,$) :- g(_,X, A), r(_, X, B), !f(A,B,_)\n",
    "\n",
    "\n",
    "hom is a real predicate\n",
    "typ(A) = hom(A,B)\n",
    "\n",
    "% these are very close to typing rules?\n",
    "\n",
    "comp(F,G) :- `hom(F,A,B), `hom(G,B,C) % finding new morphisms via composition\n",
    "otimes(A, B)  :- obj(A), obj(B)\n",
    "id(A), type(id(A)) =  :- obj(A)\n",
    "del(A) :- obj(A)\n",
    "hom(A,B) :- ob(A), ob(B)\n",
    "\n",
    "\n",
    "type(id(A)) :- type(A) = ob.\n",
    "welltyped(id(A))\n",
    "\n",
    "\n",
    "Can we encode Cody's scheme fairly directly into datalog?\n",
    "Gnerate morphisms to find paths\n",
    "Generate objects\n",
    "Instantiate equalities (the rewrite rules)\n",
    "\n",
    "\n",
    "Do everything with $?\n",
    "\n",
    "We can put together multiple stages in a single datalog file.\n",
    "\n",
    "\n",
    "\n",
    "Start my initializzed structs at negative numbers\n",
    "All generated stuff via $ is positive.\n",
    "\n",
    "objects.\n",
    "a b c\n",
    "d e f\n",
    "\n",
    "morphisms \n",
    "i j k l m n o\n",
    "\n",
    "typ(a) = ob % a lot of typing\n",
    "typ(b) = ob\n",
    "typ(i) = hom(a,b).\n",
    "typ(j) = hom(b,c).\n",
    "typ()\n",
    "\n",
    "pullback(i,j,k,).\n",
    "square :- pullback.\n",
    "pullback :- square, universal.\n",
    "\n",
    "Only equality is handled special? Other predicates have theiur terms expanded but otherwise left alone.\n",
    "\n",
    "\n",
    "id(A) :- typ(A) = ob\n",
    "comp(id(A), F) = F :- typ(F) = hom(A,B), typ(A) = \n",
    "\n",
    "typ(comp(F,G)) = hom(A,B) :- typ(F) = hom(A,B), typ(G) = hom(B,C)\n",
    "\n",
    "comp(F,G) <- typ(F) = hom(A,B), typ(G) = hom(B,C)\n",
    "\n",
    "infer generative statements from type checking?\n",
    "\n",
    "If I need to gensym something that is tied together it is a pain? intermediate predciate?\n",
    "\n",
    "gen(F,G,$) :- hom yadayda\n",
    "comp(F,G,ID) :- gen(F,G,Id,A,B)\n",
    "no -- hom(A,B,$) :- gen(F,G,Id,A,B), !hom(A,B,_)\n",
    "\n",
    "hom2(A,B,T) :- hom1(A,B,T)\n",
    "hom(A,B,$) :- typ(A) = ob, typ(B) = ob, !hom(A,B,_)\n",
    "\n",
    "typ(Id,T) :- gen(F,G,Id,A,B),  hom(A,B,T)\n",
    "\n",
    "\n",
    "g(x) = A :- A = f(y)   -- ematching one way\n",
    "A = B :- f(x) = A, g(x) = B  -- pure checking\n",
    "g(x) = f(x) :-      -- bidirectional ematching.\n",
    "\n",
    "\n",
    "\n",
    "comp(F,G) :-  typ()   -- generative of terms. makes sense since comp should really be thought of as comp(F,G,H).\n",
    "\n",
    "typ(a) = ob.\n",
    "typ(b) = ob.\n",
    "typ(f) = hom(a,b).\n",
    "\n",
    "hom(A,B) :- ob = typ(A), ob = typ(B).\n",
    "% can encode into rewrite rule using the x = x trick in egg. Or special thing?\n",
    "%\n",
    "\n",
    "typ(comp(F,G)) = hom(A,C) :- hom(A,B) = typ(F), hom(B,C) = typ(G)\n",
    "\n",
    "\n",
    "geenerate more than one thing at once\n",
    "\n",
    "f(x), g(y), yada :-  \n",
    "f(x).\n",
    "g(y).\n",
    "\n",
    "\n",
    "We can support stratified negation.\n",
    "\n",
    "term(comp(F,G)) :-  -- special pdeciate term? To enumerate all terms. Makes sense in terms of prolog. except that my \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('f', 1), ('f', 3), ('x', 0)}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "@dataclass\n",
    "class Relation():\n",
    "    head\n",
    "    args\n",
    "'''\n",
    "\n",
    "class Term():\n",
    "    def __init__(self, name, *args):\n",
    "        self.head = name\n",
    "        self.args = args\n",
    "    def __eq__(self,rhs):\n",
    "        ind1, c1 = self.flatten()\n",
    "        ind2, c2 = rhs.flatten()\n",
    "        return Term(\"equiv\", ind1, ind2), c1 + c2 \n",
    "    def flatten(self):\n",
    "        global gensym\n",
    "        if len(self.args) == 0:\n",
    "            a = gensym()\n",
    "            return a, [Term(self.head, a)]\n",
    "        res, clauses = zip( *[a.flatten() for a in self.args]   )\n",
    "        #print(self)\n",
    "        a = gensym()\n",
    "        return a, [Term(self.head, *res, a)] + [ x for c in clauses for x in c]\n",
    "    def flatten_ground(self):\n",
    "        global gensym_ground\n",
    "        if len(self.args) == 0:\n",
    "            a = gensym_ground()\n",
    "            return a, [Term(self.head, a)]\n",
    "        res, clauses = zip( *[a.flatten_ground() for a in self.args]   )\n",
    "        a = gensym_ground()\n",
    "        return a, [Term(self.head, *res, a)] + [ x for c in clauses for x in c]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if len(self.args) == 0:\n",
    "            return self.head\n",
    "        argstr = \",\".join(map(repr,self.args))\n",
    "        return f\"{self.head}({argstr})\"\n",
    "    def all_vars(self):\n",
    "        for a in self.args:\n",
    "            yield from a.all_vars()\n",
    "    def subst(self,d):\n",
    "        return Term(self.head, *[a.subst(d)  for a in self.args])\n",
    "    def symarity(self):\n",
    "        return set([(self.head, len(self.args))] + [sa for a in self.args for sa in a.symarity()])\n",
    "class Var():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def flatten(self):\n",
    "        return self, []\n",
    "    def __repr__(self):\n",
    "        return f\"?{self.name}\"\n",
    "    def all_vars(self):\n",
    "        yield self\n",
    "    def symarity(self):\n",
    "        return []\n",
    "    def subst(self,d):\n",
    "        if self.name in d:\n",
    "            return d[self.name]\n",
    "        return self\n",
    "        \n",
    "class GenSym():\n",
    "    def __init__(self, prefix=\"var\"):\n",
    "        self.index = 0\n",
    "        self.prefix = prefix\n",
    "    def __call__(self):\n",
    "        self.index += 1\n",
    "        return Var(self.prefix + str(self.index))\n",
    "gensym = GenSym()\n",
    "class GenSymGround():\n",
    "    def __init__(self, prefix=\"var\"):\n",
    "        self.index = 0\n",
    "        self.prefix = prefix\n",
    "    def __call__(self):\n",
    "        self.index += 1\n",
    "        return self.index\n",
    "gensym_ground = GenSymGround()\n",
    "#gensym()\n",
    "#gensym()\n",
    "\n",
    "f = lambda *x: Term(\"f\", *x)\n",
    "x = Term(\"x\")\n",
    "f(x,x,f(x)).flatten()\n",
    "\n",
    "f(x) == f(x,x)\n",
    "\n",
    "a = Var(\"a\")\n",
    "list(f(a,x,a).all_vars())\n",
    "f(a,x,f(a)).flatten()\n",
    "b = Var(\"b\")\n",
    "\n",
    "f(a,b).subst({\"a\" : x, \"b\" : a})\n",
    "f(x,x).flatten_ground()\n",
    "f(x,x,f(x)).symarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Systems:\n",
    "Seen work:\n",
    "  - Kozen had a thing\n",
    "  - There is a chunk in thge ATP porblem database\n",
    "\n",
    "Interactive Theorem: Coq, Agda, that list of theorem prover catgeory projects\n",
    "Automated Solvers:\n",
    "  ATP: E, Vampire -= resolution / DPlike\n",
    "  SMT: Z3, CVC4 Boolector - DPLL like\n",
    "  SAT: \n",
    "  CSP: minizinc\n",
    "Logic Programming:\n",
    "    - Datalog\n",
    "    - Prolog\n",
    "    - Minikanren\n",
    "    - Lambda prolog\n",
    "    - Ltac / Auto?\n",
    "Computer Algebra:\n",
    "    - methetmatica, maxima, reduce, sympy\n",
    "    - Computatioal Group Theory:\n",
    "    - Singular\n",
    "Term rewriting:\n",
    "    - mathamtica , others\n",
    "    - egg/metathoery\n",
    "    - knuth bendix?\n",
    "Other:\n",
    "  knuth bendix\n",
    "  Term rewriting\n",
    "  Graph rewriting\n",
    "  Graph isomorphism\n",
    "  Probably not relevant:\n",
    "  TSP traveling salesman\n",
    "  MIP\n",
    "  Linear programming?\n",
    "  Egg/Metatheory\n",
    " \n",
    "\n",
    "Build it or Buy it\n",
    "\n",
    "\n",
    "First Try:\n",
    "  many FOL encodings fro tha youtube video\n",
    "  compose is partial\n",
    "  \n",
    "Theme: Static vs Dynamic types\n",
    " - That one paper about encoding typed stuff\n",
    " - analogy to typed computer systems.\n",
    "\n",
    "SMT Attempt:\n",
    " -\n",
    " - \n",
    "\n",
    "\n",
    "EGraphs:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To Graph or Not:\n",
    "- diagrammatics are the awesome power of CT\n",
    "- But diagrams are paper and pencil, we need to create discrete structures for computers. Kind of kills the whole thing\n",
    "\n",
    "\n",
    "The egraph as pasting diagrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f(x,y,z) :- f(z)', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('f', ['x', 'y', 'z'])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def parse_relation(rel):\n",
    "    m = re.match(r\"(?P<head>\\w+)\\((?P<args>[^\\)]+)\\)\", rel)\n",
    "    args = m.group(\"args\").split(\",\")\n",
    "    head = m.group(\"head\")\n",
    "    return head, args\n",
    "\n",
    "\n",
    "\n",
    "def parse_clause(clause):\n",
    "    head, body = clause.split(\":-\")\n",
    "    return parse_relation(head) #, [  for c in body.split(\",\") ]\n",
    "\n",
    "def parse(text):\n",
    "    text = text.strip()\n",
    "    clauses = text.split(\".\")\n",
    "    print(clauses)\n",
    "    assert clauses[-1] == \"\"\n",
    "    clauses = clauses[:-1]\n",
    "    return [ parse_clause(c)    for c in clauses   ]\n",
    "\n",
    "parse_relation(\"f(x,y,z)\")\n",
    "parse(\"f(x,y,z) :- f(z).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-0b4403562722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "x,y = (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(equiv(?var20,?var21),\n",
       " [f(?var14,?var15,?var16,?var20),\n",
       "  f(?var17,?var18,?var19,?var21),\n",
       "  equiv(?var14,?var17),\n",
       "  equiv(?var15,?var18),\n",
       "  equiv(?var16,?var19)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Clause(head=EqRel(lhs=?var135, rhs=?var136), body=[f(?var134,?var135), x(?var134), f(?a,?var136), f(?var137,?var138,?var139), x(?var137), x(?var138)])],\n",
       " [Clause(head=EqRel(lhs=?var126, rhs=?var127), body=[f(?var122,?var123,?var126), f(?var124,?var125,?var127), EqRel(lhs=?var122, rhs=?var124), EqRel(lhs=?var123, rhs=?var125)]),\n",
       "  Clause(head=EqRel(lhs=?var128, rhs=?var129), body=[x(?var128), x(?var129)]),\n",
       "  Clause(head=EqRel(lhs=?var132, rhs=?var133), body=[f(?var130,?var132), f(?var131,?var133), EqRel(lhs=?var130, rhs=?var131)])])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are program? Let's start with a set of clauses.\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EqRel:\n",
    "    lhs: Term\n",
    "    rhs: Term\n",
    "\n",
    "@dataclass\n",
    "class Clause:\n",
    "    head: EqRel\n",
    "    body: List[EqRel]\n",
    "\n",
    "@dataclass\n",
    "class Program:\n",
    "    clauses: List[Clause]\n",
    "        \n",
    "def compile_eqrel(r : EqRel):\n",
    "    tid1, c1 = r.lhs.flatten()\n",
    "    tid2, c2 = r.rhs.flatten()\n",
    "    return EqRel(tid1,tid2), c1 + c2\n",
    "        \n",
    "def compile_clause(c : Clause):\n",
    "    newhead, c1 = compile_eqrel(c.head)\n",
    "    c2 = [flatrel for r in c.body for flatrel in compile_eqrel(r)[1]]\n",
    "    return Clause(newhead, c1 + c2)\n",
    "\n",
    "def symarity_eqrel(r):\n",
    "    return set.union(r.lhs.symarity() , r.rhs.symarity())\n",
    "\n",
    "def symarity_clause(c):\n",
    "    return set.union( symarity_eqrel(c.head) , [x for r in c.body for x in symarity_eqrel(r)])\n",
    "\n",
    "def declaration(sym,arity):\n",
    "    args = \",\".join([ f\"{gensym()} : number\" for i in range(arity) ])\n",
    "    return f\".decl {sym}({args})\"\n",
    "\n",
    "def congruence(sym, arity):\n",
    "    args1 = [gensym() for i in range(arity)]\n",
    "    args2 = [gensym() for i in range(arity)]\n",
    "    a1 = gensym()\n",
    "    a2 = gensym()\n",
    "    t1 = Term(sym, *args1, a1)\n",
    "    t2 = Term(sym, *args2, a2)\n",
    "    conds = map( lambda a: EqRel(a[0],a[1]) ,  zip(args1,args2))\n",
    "    return Clause(EqRel( a1, a2), [t1, t2] + list(conds))\n",
    "\n",
    "\n",
    "def compile_prog(p : Program):\n",
    "    #symarity = build_symarity(p)\n",
    "    symarity = [  sa for clause in p.clauses for sa in symarity_clause(clause) ]\n",
    "    d = [  declaration(sym, arity + 1)   for (sym, arity) in symarity]\n",
    "    ins = [f\".input {sym}\" for (sym,arity) in symarity]\n",
    "    c = [  congruence(sym,  arity)   for (sym, arity) in symarity]\n",
    "    eqs = [  compile_clause(clause) for clause in p.clauses ]\n",
    "    return eqs, c\n",
    "\n",
    "\n",
    "p = Program( [  Clause( EqRel( f(x), f(a)  ), [EqRel(f(x,x), a)]  )  ] )\n",
    "compile_prog(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prolog = '''\n",
    "\n",
    ".decl equiv(n: number, m : number) eqrel\n",
    ".output equiv\n",
    "'''\n",
    "\n",
    "\n",
    "def declaration(sym,arity):\n",
    "    args = \",\".join([ f\"{gensym()} : number\" for range(arity)  ])\n",
    "    return f\".decl {sym}({args})\"\n",
    "\n",
    "\n",
    "# This builds the datalog program for just the egraph structure\n",
    "def declares(symarity):\n",
    "    d = [  declaration(sym, arity)   for (sym, arity) in symarity]\n",
    "    ins = [f\".input {sym}\" for (sym,arity) in symarity]\n",
    "    c = [  congruence(sym,  arity)   for (sym, arity) in symarity]\n",
    "    \n",
    "    # output summaries? compression?\n",
    "    # \n",
    "    return \"\\n\".join( [prolog] + d + c )\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(mypat(?a,?var27), [f(?a,?var26,?var27), f(?var25,?a,?var26), x(?var25)])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pattern(rule_name, lhs):\n",
    "    vs = list(set(lhs.all_vars()))\n",
    "    lhsid, c = lhs.flatten()\n",
    "    return Term(rule_name, *vs, lhsid), c\n",
    "pattern(\"mypat\", f(a,f(x,a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe there is a way to internalize this into datalog,, if there is a way to get the canonical element out of equiv.\n",
    "\n",
    "# ok actually I can do this.\n",
    "def rebuild(equiv, f): # restabilish hash cons invaraint ish.\n",
    "    for row in f:\n",
    "        normalize(row, f)\n",
    "        \n",
    "# We can dumb instantiate\n",
    "# rhs should already be flat.\n",
    "\n",
    "def instnantiate_pattern(pat_table, rhs):\n",
    "    for row in pat_table:\n",
    "        rhs = rhs.subst( row )\n",
    "        rhs.flatten()\n",
    "        \n",
    "# The equality queires should be tables that if non empty means we've found the eqaulity of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_clause(clause):\n",
    "    props = set(   clause.body.rel) + set(clause.head.rel)\n",
    "def run_datalog(clauses, pds):\n",
    "    # wrtie to files?  pd.csv()\n",
    "    # read in.\n",
    "def run\n",
    "\n",
    "def compile_term_clause( c):\n",
    "    map(flatten , c.head.args)\n",
    "    newhead = Relation(c.head.name, *inds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fred</th>\n",
       "      <th>larry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fred  larry\n",
       "0     8      9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"fred\": [8] , \"larry\" : [9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relation(pd.DataFrame):\n",
    "    def init(self, name, *args, **kwargs):        \n",
    "        self.name = name\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def __call__(self, *args):\n",
    "        return Prop(self, *args)\n",
    "        \n",
    "foo = Relation(foo, columns=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, 7]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns=range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
